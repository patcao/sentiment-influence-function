{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d962785-65b7-4e44-8c74-a114a8faa825",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T02:14:02.313075Z",
     "iopub.status.busy": "2023-05-02T02:14:02.312840Z",
     "iopub.status.idle": "2023-05-02T02:14:03.329597Z",
     "shell.execute_reply": "2023-05-02T02:14:03.328846Z",
     "shell.execute_reply.started": "2023-05-02T02:14:02.313060Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:00<00:00, 14475.99it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 872/872 [00:00<00:00, 10838.25it/s]\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import src.BertClassifier as BertClassifier\n",
    "import src.utils as utils\n",
    "import torch\n",
    "import yaml\n",
    "from src.datasets import create_loo_dataset, create_test_sst2, create_train_sst2\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "import wandb\n",
    "\n",
    "device = utils.get_device()\n",
    "config_path = \"loo/classifier.yaml\"\n",
    "epochs = 3\n",
    "num_training_examples = 10000\n",
    "\n",
    "with open(config_path, \"r\") as stream:\n",
    "    config = yaml.safe_load(stream)\n",
    "config.update({\"epochs\": epochs, \"num_training_examples\": num_training_examples})\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = create_train_sst2(\n",
    "    device,\n",
    "    num_samples=config[\"num_training_examples\"],\n",
    "    tokenizer_name=config[\"bert_model_name\"],\n",
    "    max_seq_len=config[\"max_sequence_length\"],\n",
    ")\n",
    "\n",
    "test_dataset = create_test_sst2(\n",
    "    device,\n",
    "    tokenizer_name=config[\"bert_model_name\"],\n",
    "    max_seq_len=config[\"max_sequence_length\"],\n",
    ")\n",
    "test_dataloader = DataLoader(test_dataset, shuffle=False, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5f0a57-22fe-45ec-b0be-dd685a0ae0b0",
   "metadata": {},
   "source": [
    "## Full Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "650bbd48-baaa-4cdf-b941-a9b3cdc64d33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T01:59:27.688310Z",
     "iopub.status.busy": "2023-05-02T01:59:27.688059Z",
     "iopub.status.idle": "2023-05-02T02:00:26.530658Z",
     "shell.execute_reply": "2023-05-02T02:00:26.529687Z",
     "shell.execute_reply.started": "2023-05-02T01:59:27.688292Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_projector.bias', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpatcao\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/pcao/sentiment-influence-function/wandb/run-20230501_215929-xb2s054u</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/patcao/LOO-test/runs/xb2s054u' target=\"_blank\">comfy-grass-63</a></strong> to <a href='https://wandb.ai/patcao/LOO-test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/patcao/LOO-test' target=\"_blank\">https://wandb.ai/patcao/LOO-test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/patcao/LOO-test/runs/xb2s054u' target=\"_blank\">https://wandb.ai/patcao/LOO-test/runs/xb2s054u</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 625/625 [00:22<00:00, 27.73batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 625/625 [00:21<00:00, 28.54batch/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0dd6f78fcc84eafb25bbf4000ece77d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.003 MB of 0.013 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.213530…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁█</td></tr><tr><td>train/accuracy</td><td>▁█</td></tr><tr><td>train/batch_loss</td><td>█▇▇▅▅▃▄▇▆▇▅▃▃▄▄▂▄▂▆▁█▂▄▁▂▅▂█▁▆█▂▄▂▅▆▃▁▃▅</td></tr><tr><td>train/loss</td><td>█▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>2</td></tr><tr><td>test/accuracy</td><td>83.37156</td></tr><tr><td>test/loss</td><td>0.37996</td></tr><tr><td>train/accuracy</td><td>83.18</td></tr><tr><td>train/batch_loss</td><td>0.11154</td></tr><tr><td>train/loss</td><td>0.37465</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">comfy-grass-63</strong> at: <a href='https://wandb.ai/patcao/LOO-test/runs/xb2s054u' target=\"_blank\">https://wandb.ai/patcao/LOO-test/runs/xb2s054u</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230501_215929-xb2s054u/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# loo_dataset = create_loo_dataset(train_dataset, 0)\n",
    "# train_dataloader = DataLoader(\n",
    "#     loo_dataset, batch_size=config[\"batch_size\"], shuffle=True\n",
    "# )\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, batch_size=config[\"batch_size\"], shuffle=True\n",
    ")\n",
    "\n",
    "# Create classifcation model\n",
    "full_model = BertClassifier.create_bert_classifier(\n",
    "    config[\"bert_model_name\"],\n",
    "    classifier_type=config[\"classifier_type\"],\n",
    "    classifier_hidden_size=config[\"classifier_hidden_size\"],\n",
    "    classifier_drop_out=config[\"classifier_drop_out\"],\n",
    "    freeze_bert=True,\n",
    "    random_state=42,\n",
    ")\n",
    "full_model.classifier.load_state_dict(\n",
    "    torch.load(\"loo_10k/run_0/init_classifier_params.pt\")\n",
    ")\n",
    "# torch.save(model.classifier.state_dict(), 'classifier_params.pt')\n",
    "\n",
    "optimizer = Adam(full_model.classifier.parameters(), lr=config[\"learning_rate\"])\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "run = wandb.init(project=\"LOO-test\", tags=[\"full\"], config=config)\n",
    "\n",
    "timings = utils.train(\n",
    "    config=config,\n",
    "    model=full_model,\n",
    "    optimizer=optimizer,\n",
    "    loss_fn=loss_fn,\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloader=None,\n",
    ")\n",
    "\n",
    "test_loss, test_acc = utils.evaluate(full_model, test_dataloader)\n",
    "wandb.summary[\"test/loss\"] = test_loss\n",
    "wandb.summary[\"test/accuracy\"] = test_acc\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90380bb3-cbae-41cb-9e88-4ef79620814c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T02:00:26.531894Z",
     "iopub.status.busy": "2023-05-02T02:00:26.531562Z",
     "iopub.status.idle": "2023-05-02T02:00:31.972993Z",
     "shell.execute_reply": "2023-05-02T02:00:31.972292Z",
     "shell.execute_reply.started": "2023-05-02T02:00:26.531873Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_guid</th>\n",
       "      <th>label</th>\n",
       "      <th>pred</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.004901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.063696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.011256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.058076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.170423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>867</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.938666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>868</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.581234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>869</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.234386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>870</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.404960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>871</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.033994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>872 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     test_guid  label  pred      loss\n",
       "0            0      1     1  0.004901\n",
       "1            1      0     0  0.063696\n",
       "2            2      1     1  0.011256\n",
       "3            3      1     1  0.058076\n",
       "4            4      0     0  0.170423\n",
       "..         ...    ...   ...       ...\n",
       "867        867      0     1  0.938666\n",
       "868        868      1     1  0.581234\n",
       "869        869      0     1  1.234386\n",
       "870        870      0     0  0.404960\n",
       "871        871      1     1  0.033994\n",
       "\n",
       "[872 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute loss for each test point\n",
    "fdf = utils.evaluate_loss_df(full_model, test_dataloader)\n",
    "fdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "608fbed1-9ade-448b-8d2b-d9235db3451a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T02:00:31.973998Z",
     "iopub.status.busy": "2023-05-02T02:00:31.973799Z",
     "iopub.status.idle": "2023-05-02T02:00:31.999071Z",
     "shell.execute_reply": "2023-05-02T02:00:31.998331Z",
     "shell.execute_reply.started": "2023-05-02T02:00:31.973983Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_guid</th>\n",
       "      <th>label</th>\n",
       "      <th>pred</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>869</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.234386</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     test_guid  label  pred      loss\n",
       "869        869      0     1  1.234386"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdf[fdf.test_guid == 869]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1898072f-387a-4139-b42f-7f5c8d311125",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T02:00:31.999985Z",
     "iopub.status.busy": "2023-05-02T02:00:31.999774Z",
     "iopub.status.idle": "2023-05-02T02:00:32.026204Z",
     "shell.execute_reply": "2023-05-02T02:00:32.025492Z",
     "shell.execute_reply.started": "2023-05-02T02:00:31.999967Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_guid</th>\n",
       "      <th>label</th>\n",
       "      <th>pred</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>869</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.234386</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     test_guid  label  pred      loss\n",
       "869        869      0     1  1.234386"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdf[fdf.test_guid == 869]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063e39d7-3b87-4ce9-89e6-a4125fd674ae",
   "metadata": {
    "tags": []
   },
   "source": [
    "## LOO Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f23f7b03-c23c-4ec9-bcea-d109638f8058",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T02:00:32.026951Z",
     "iopub.status.busy": "2023-05-02T02:00:32.026768Z",
     "iopub.status.idle": "2023-05-02T02:00:32.048053Z",
     "shell.execute_reply": "2023-05-02T02:00:32.047491Z",
     "shell.execute_reply.started": "2023-05-02T02:00:32.026936Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, TensorDataset\n",
    "\n",
    "\n",
    "def create_loo_dataset(sst2_dataset, loo_guid):\n",
    "    guids, inputs, masks, labels = sst2_dataset.tensors\n",
    "    loo_mask = ~(guids == loo_guid)\n",
    "    return TensorDataset(\n",
    "        guids[loo_mask], inputs[loo_mask], masks[loo_mask], labels[loo_mask]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658a67b5-f5c8-4387-a5fb-f183040360f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T02:21:48.391559Z",
     "iopub.status.busy": "2023-05-02T02:21:48.391326Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_projector.bias', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/pcao/sentiment-influence-function/wandb/run-20230501_222149-7fwevqdx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/patcao/LOO-test/runs/7fwevqdx' target=\"_blank\">morning-paper-76</a></strong> to <a href='https://wandb.ai/patcao/LOO-test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/patcao/LOO-test' target=\"_blank\">https://wandb.ai/patcao/LOO-test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/patcao/LOO-test/runs/7fwevqdx' target=\"_blank\">https://wandb.ai/patcao/LOO-test/runs/7fwevqdx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 625/625 [00:22<00:00, 28.18batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 625/625 [00:21<00:00, 28.76batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 625/625 [00:21<00:00, 28.63batch/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▅█</td></tr><tr><td>train/accuracy</td><td>▁▇█</td></tr><tr><td>train/batch_loss</td><td>▅▅▄▄▄▃▄▃▁▅▄▃▃▃▆▂▄▂▅▂▃▄▃▆▂▅▄▂▃▃▁▂▂▄▂▂▃▂█▂</td></tr><tr><td>train/loss</td><td>█▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>3</td></tr><tr><td>test/accuracy</td><td>83.1422</td></tr><tr><td>test/loss</td><td>0.38197</td></tr><tr><td>train/accuracy</td><td>83.83867</td></tr><tr><td>train/batch_loss</td><td>0.04381</td></tr><tr><td>train/loss</td><td>0.36695</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">morning-paper-76</strong> at: <a href='https://wandb.ai/patcao/LOO-test/runs/7fwevqdx' target=\"_blank\">https://wandb.ai/patcao/LOO-test/runs/7fwevqdx</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230501_222149-7fwevqdx/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_projector.bias', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/pcao/sentiment-influence-function/wandb/run-20230501_222313-8ersxk0a</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/patcao/LOO-test/runs/8ersxk0a' target=\"_blank\">major-rain-77</a></strong> to <a href='https://wandb.ai/patcao/LOO-test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/patcao/LOO-test' target=\"_blank\">https://wandb.ai/patcao/LOO-test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/patcao/LOO-test/runs/8ersxk0a' target=\"_blank\">https://wandb.ai/patcao/LOO-test/runs/8ersxk0a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 625/625 [00:22<00:00, 28.26batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 625/625 [00:22<00:00, 28.29batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 625/625 [00:22<00:00, 27.92batch/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b7e53e770714c5ca4316c67fa6b5460",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.003 MB of 0.014 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.194228…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▅█</td></tr><tr><td>train/accuracy</td><td>▁▇█</td></tr><tr><td>train/batch_loss</td><td>▅▅▄▄▄▃▄▃▁▅▄▃▃▃▆▂▄▂▅▂▃▄▃▆▂▅▄▂▃▃▁▂▂▄▂▂▃▂█▂</td></tr><tr><td>train/loss</td><td>█▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>3</td></tr><tr><td>test/accuracy</td><td>83.25688</td></tr><tr><td>test/loss</td><td>0.38207</td></tr><tr><td>train/accuracy</td><td>83.85867</td></tr><tr><td>train/batch_loss</td><td>0.04374</td></tr><tr><td>train/loss</td><td>0.36699</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">major-rain-77</strong> at: <a href='https://wandb.ai/patcao/LOO-test/runs/8ersxk0a' target=\"_blank\">https://wandb.ai/patcao/LOO-test/runs/8ersxk0a</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230501_222313-8ersxk0a/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_projector.bias', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/pcao/sentiment-influence-function/wandb/run-20230501_222438-lcig1tdt</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/patcao/LOO-test/runs/lcig1tdt' target=\"_blank\">autumn-disco-78</a></strong> to <a href='https://wandb.ai/patcao/LOO-test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/patcao/LOO-test' target=\"_blank\">https://wandb.ai/patcao/LOO-test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/patcao/LOO-test/runs/lcig1tdt' target=\"_blank\">https://wandb.ai/patcao/LOO-test/runs/lcig1tdt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 625/625 [00:22<00:00, 27.96batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 625/625 [00:22<00:00, 27.82batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 625/625 [00:22<00:00, 27.84batch/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f019182395004cd0b253f08eca1b0b1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.003 MB of 0.003 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▅█</td></tr><tr><td>train/accuracy</td><td>▁▇█</td></tr><tr><td>train/batch_loss</td><td>▅▅▄▄▄▃▄▃▁▅▄▃▃▃▆▂▄▂▅▂▃▄▃▆▂▅▄▂▃▃▁▂▂▄▂▂▃▂█▂</td></tr><tr><td>train/loss</td><td>█▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>3</td></tr><tr><td>test/accuracy</td><td>83.25688</td></tr><tr><td>test/loss</td><td>0.38208</td></tr><tr><td>train/accuracy</td><td>83.86867</td></tr><tr><td>train/batch_loss</td><td>0.04371</td></tr><tr><td>train/loss</td><td>0.36699</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">autumn-disco-78</strong> at: <a href='https://wandb.ai/patcao/LOO-test/runs/lcig1tdt' target=\"_blank\">https://wandb.ai/patcao/LOO-test/runs/lcig1tdt</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230501_222438-lcig1tdt/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_projector.bias', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/pcao/sentiment-influence-function/wandb/run-20230501_222605-34rx7n4o</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/patcao/LOO-test/runs/34rx7n4o' target=\"_blank\">rosy-forest-79</a></strong> to <a href='https://wandb.ai/patcao/LOO-test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/patcao/LOO-test' target=\"_blank\">https://wandb.ai/patcao/LOO-test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/patcao/LOO-test/runs/34rx7n4o' target=\"_blank\">https://wandb.ai/patcao/LOO-test/runs/34rx7n4o</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 625/625 [00:22<00:00, 27.77batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 625/625 [00:22<00:00, 27.92batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 625/625 [00:21<00:00, 28.53batch/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c5de0290d6c4649870bf1f1bad04303",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.003 MB of 0.004 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.735468…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▅█</td></tr><tr><td>train/accuracy</td><td>▁▇█</td></tr><tr><td>train/batch_loss</td><td>▅▅▄▄▄▃▄▃▁▅▄▃▃▃▆▂▄▂▅▂▃▄▃▆▂▅▄▂▃▃▁▂▂▄▂▂▃▂█▂</td></tr><tr><td>train/loss</td><td>█▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>3</td></tr><tr><td>test/accuracy</td><td>83.25688</td></tr><tr><td>test/loss</td><td>0.38185</td></tr><tr><td>train/accuracy</td><td>83.87867</td></tr><tr><td>train/batch_loss</td><td>0.04357</td></tr><tr><td>train/loss</td><td>0.36673</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">rosy-forest-79</strong> at: <a href='https://wandb.ai/patcao/LOO-test/runs/34rx7n4o' target=\"_blank\">https://wandb.ai/patcao/LOO-test/runs/34rx7n4o</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230501_222605-34rx7n4o/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_projector.bias', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/pcao/sentiment-influence-function/wandb/run-20230501_222730-5e89f9vt</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/patcao/LOO-test/runs/5e89f9vt' target=\"_blank\">summer-butterfly-80</a></strong> to <a href='https://wandb.ai/patcao/LOO-test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/patcao/LOO-test' target=\"_blank\">https://wandb.ai/patcao/LOO-test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/patcao/LOO-test/runs/5e89f9vt' target=\"_blank\">https://wandb.ai/patcao/LOO-test/runs/5e89f9vt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|██████████████████████████████████████████████▋                                                 | 304/625 [00:10<00:11, 28.64batch/s]"
     ]
    }
   ],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "loo_dfs = []\n",
    "\n",
    "for loo_guid in range(0, 5):\n",
    "    loo_dataset = create_loo_dataset(train_dataset, loo_guid)\n",
    "    loo_train_dataloader = DataLoader(\n",
    "        loo_dataset, batch_size=config[\"batch_size\"], shuffle=True\n",
    "    )\n",
    "\n",
    "    # Create classifcation model\n",
    "    loo_model = BertClassifier.create_bert_classifier(\n",
    "        config[\"bert_model_name\"],\n",
    "        classifier_type=config[\"classifier_type\"],\n",
    "        classifier_hidden_size=config[\"classifier_hidden_size\"],\n",
    "        classifier_drop_out=config[\"classifier_drop_out\"],\n",
    "        freeze_bert=True,\n",
    "        random_state=42,\n",
    "    )\n",
    "\n",
    "    optimizer = Adam(loo_model.classifier.parameters(), lr=config[\"learning_rate\"])\n",
    "    run = wandb.init(project=\"LOO-test\", tags=[\"full\"], config=config)\n",
    "\n",
    "    timings = utils.train(\n",
    "        config=config,\n",
    "        model=loo_model,\n",
    "        optimizer=optimizer,\n",
    "        loss_fn=loss_fn,\n",
    "        train_dataloader=loo_train_dataloader,\n",
    "        val_dataloader=None,\n",
    "    )\n",
    "\n",
    "    test_loss, test_acc = utils.evaluate(loo_model, test_dataloader)\n",
    "    wandb.summary[\"test/loss\"] = test_loss\n",
    "    wandb.summary[\"test/accuracy\"] = test_acc\n",
    "    wandb.finish()\n",
    "\n",
    "    # Compute loss for each test point\n",
    "    df = utils.evaluate_loss_df(loo_model, test_dataloader)\n",
    "    df[\"loo_guid\"] = loo_guid\n",
    "    loo_dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a21fbba-2da6-4dc5-90e6-f05b3aa29f7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ldf = pd.concat(loo_dfs, axis=0)\n",
    "# ldf = pd.concat([pd.read_csv('exps/loo_df.csv'), ldf], axis=0)\n",
    "# ldf[\"loss_diff\"] = ldf[\"loss\"] - fdf[fdf.test_guid == test_guid].loss.squeeze()\n",
    "# ldf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cca28c-b19d-4cde-893d-887da842bc28",
   "metadata": {},
   "source": [
    "## Compute Influence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ece8c18-928f-45d5-93d6-70c3c84a92fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T02:11:04.680500Z",
     "iopub.status.busy": "2023-05-02T02:11:04.680331Z",
     "iopub.status.idle": "2023-05-02T02:11:04.702336Z",
     "shell.execute_reply": "2023-05-02T02:11:04.701597Z",
     "shell.execute_reply.started": "2023-05-02T02:11:04.680485Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import src.influence as inf_utils\n",
    "# import torch.autograd as autograd\n",
    "\n",
    "# test_guid = 869\n",
    "# param_influence = list(full_model.classifier.parameters())\n",
    "# influences = np.zeros(len(train_dataset))\n",
    "\n",
    "# for guid, input_ids, input_mask, label_ids in test_dataloader:\n",
    "#     if guid != test_guid:\n",
    "#         continue\n",
    "\n",
    "#     full_model.eval()\n",
    "#     utils.set_seed(42)\n",
    "#     train_dataloader = DataLoader(train_dataset, shuffle=False, batch_size=1)\n",
    "#     train_dataloader_lissa = DataLoader(\n",
    "#         train_dataset, batch_size=config[\"batch_size\"], shuffle=True, drop_last=True\n",
    "#     )\n",
    "\n",
    "#     input_ids = input_ids.to(device)\n",
    "#     input_mask = input_mask.to(device)\n",
    "#     label_ids = label_ids.to(device)\n",
    "\n",
    "#     # L_TEST gradient\n",
    "#     full_model.zero_grad()\n",
    "#     output = full_model(input_ids, input_mask)\n",
    "#     test_loss = loss_fn(output, label_ids)\n",
    "#     test_grads = autograd.grad(test_loss, param_influence)\n",
    "\n",
    "#     # IVHP\n",
    "#     full_model.train()\n",
    "\n",
    "#     t = int(len(train_dataloader) * 0.25)\n",
    "#     # r = int(len(train_dataloader) / t)\n",
    "#     r = 1\n",
    "#     print(f\"Using r: {r} and t: {t}\")\n",
    "\n",
    "#     inverse_hvp = inf_utils.get_inverse_hvp_lissa(\n",
    "#         test_grads,\n",
    "#         full_model,\n",
    "#         device,\n",
    "#         param_influence,\n",
    "#         train_dataloader_lissa,\n",
    "#         damping=3e-3,\n",
    "#         scale=1e4,\n",
    "#         num_samples=r,\n",
    "#         recursion_depth=t,\n",
    "#     )\n",
    "\n",
    "#     for train_guid, train_input_id, train_input_mask, train_label in tqdm(\n",
    "#         train_dataloader\n",
    "#     ):\n",
    "#         full_model.train()\n",
    "#         full_model.zero_grad()\n",
    "#         train_output = full_model(train_input_id, train_input_mask)\n",
    "#         train_loss = loss_fn(train_output, train_label)\n",
    "#         train_grads = autograd.grad(train_loss, param_influence)\n",
    "#         influences[train_guid] = torch.dot(\n",
    "#             inverse_hvp, inf_utils.gather_flat_grad(train_grads)\n",
    "#         ).item()\n",
    "\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca428991-0d45-4a12-ba67-0c23e47397cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T02:11:04.703763Z",
     "iopub.status.busy": "2023-05-02T02:11:04.703578Z",
     "iopub.status.idle": "2023-05-02T02:13:31.486904Z",
     "shell.execute_reply": "2023-05-02T02:13:31.486147Z",
     "shell.execute_reply.started": "2023-05-02T02:11:04.703749Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LiSSA reps: 1 and num_iterations: 2500\n",
      "Recursion at depth 0: norm is 23.792892\n",
      "Recursion at depth 200: norm is 1463.629517\n",
      "Recursion at depth 400: norm is 1998.025513\n",
      "Recursion at depth 600: norm is 2208.230469\n",
      "Recursion at depth 800: norm is 2318.055908\n",
      "Recursion at depth 1000: norm is 2370.135498\n",
      "Recursion at depth 1200: norm is 2390.668945\n",
      "Recursion at depth 1400: norm is 2399.083008\n",
      "Recursion at depth 1600: norm is 2402.173828\n",
      "Recursion at depth 1800: norm is 2407.013428\n",
      "Recursion at depth 2000: norm is 2397.940430\n",
      "Recursion at depth 2200: norm is 2412.884521\n",
      "Recursion at depth 2400: norm is 2411.270264\n",
      "Recursion at depth 2499: norm is 2415.950439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [01:05<00:00, 151.76it/s]\n"
     ]
    }
   ],
   "source": [
    "import src.influence as inf_utils\n",
    "\n",
    "test_guid = 869\n",
    "param_infl = list(full_model.classifier.parameters())\n",
    "infl = inf_utils.compute_influence(\n",
    "    full_model=full_model,\n",
    "    test_guid=test_guid,\n",
    "    param_influence=param_infl,\n",
    "    train_dataset=train_dataset,\n",
    "    test_dataset=test_dataset,\n",
    "    lissa_r=1,\n",
    "    lissa_depth=0.25,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00b71ea-f9bd-4aef-be51-cce0f410c0ad",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5fdf60-24dc-4d98-b655-ce905772c9a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_guid = 869\n",
    "\n",
    "#ldf = pd.read_csv(\"loo_10k/all_loo_losses.csv\")\n",
    "ldf = ldf[ldf.test_guid == test_guid]\n",
    "ldf[\"loss_diff\"] = ldf[\"loss\"] - fdf[fdf.test_guid == test_guid].loss.squeeze()\n",
    "ldf[\"if_diff\"] = (-100.0 / len(train_dataset)) * infl[:5]\n",
    "ldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e478fdd6-005e-4928-bfdf-98a68043c95c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T02:13:40.102336Z",
     "iopub.status.busy": "2023-05-02T02:13:40.102104Z",
     "iopub.status.idle": "2023-05-02T02:13:40.138435Z",
     "shell.execute_reply": "2023-05-02T02:13:40.137729Z",
     "shell.execute_reply.started": "2023-05-02T02:13:40.102321Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loo_guid</th>\n",
       "      <th>test_guid</th>\n",
       "      <th>label</th>\n",
       "      <th>loss</th>\n",
       "      <th>loss_diff</th>\n",
       "      <th>if_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>0</td>\n",
       "      <td>869</td>\n",
       "      <td>0</td>\n",
       "      <td>1.888133</td>\n",
       "      <td>0.653746</td>\n",
       "      <td>-0.001626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1741</th>\n",
       "      <td>1</td>\n",
       "      <td>869</td>\n",
       "      <td>0</td>\n",
       "      <td>1.888622</td>\n",
       "      <td>0.654235</td>\n",
       "      <td>-0.001123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2613</th>\n",
       "      <td>2</td>\n",
       "      <td>869</td>\n",
       "      <td>0</td>\n",
       "      <td>1.888152</td>\n",
       "      <td>0.653765</td>\n",
       "      <td>0.000207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3485</th>\n",
       "      <td>3</td>\n",
       "      <td>869</td>\n",
       "      <td>0</td>\n",
       "      <td>1.863295</td>\n",
       "      <td>0.628909</td>\n",
       "      <td>-0.017191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4357</th>\n",
       "      <td>4</td>\n",
       "      <td>869</td>\n",
       "      <td>0</td>\n",
       "      <td>1.866936</td>\n",
       "      <td>0.632549</td>\n",
       "      <td>-0.001228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5229</th>\n",
       "      <td>5</td>\n",
       "      <td>869</td>\n",
       "      <td>0</td>\n",
       "      <td>1.867203</td>\n",
       "      <td>0.632817</td>\n",
       "      <td>-0.004064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6101</th>\n",
       "      <td>6</td>\n",
       "      <td>869</td>\n",
       "      <td>0</td>\n",
       "      <td>1.865716</td>\n",
       "      <td>0.631330</td>\n",
       "      <td>0.000959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6973</th>\n",
       "      <td>7</td>\n",
       "      <td>869</td>\n",
       "      <td>0</td>\n",
       "      <td>1.865781</td>\n",
       "      <td>0.631395</td>\n",
       "      <td>0.005427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7845</th>\n",
       "      <td>8</td>\n",
       "      <td>869</td>\n",
       "      <td>0</td>\n",
       "      <td>1.864583</td>\n",
       "      <td>0.630196</td>\n",
       "      <td>-0.002895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8717</th>\n",
       "      <td>9</td>\n",
       "      <td>869</td>\n",
       "      <td>0</td>\n",
       "      <td>1.868037</td>\n",
       "      <td>0.633650</td>\n",
       "      <td>0.018015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9589</th>\n",
       "      <td>10</td>\n",
       "      <td>869</td>\n",
       "      <td>0</td>\n",
       "      <td>1.871785</td>\n",
       "      <td>0.637399</td>\n",
       "      <td>-0.004448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10461</th>\n",
       "      <td>11</td>\n",
       "      <td>869</td>\n",
       "      <td>0</td>\n",
       "      <td>1.873724</td>\n",
       "      <td>0.639338</td>\n",
       "      <td>-0.000542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11333</th>\n",
       "      <td>12</td>\n",
       "      <td>869</td>\n",
       "      <td>0</td>\n",
       "      <td>1.872625</td>\n",
       "      <td>0.638238</td>\n",
       "      <td>-0.007426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12205</th>\n",
       "      <td>13</td>\n",
       "      <td>869</td>\n",
       "      <td>0</td>\n",
       "      <td>1.868625</td>\n",
       "      <td>0.634238</td>\n",
       "      <td>-0.003394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13077</th>\n",
       "      <td>14</td>\n",
       "      <td>869</td>\n",
       "      <td>0</td>\n",
       "      <td>1.866474</td>\n",
       "      <td>0.632087</td>\n",
       "      <td>-0.010099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13949</th>\n",
       "      <td>15</td>\n",
       "      <td>869</td>\n",
       "      <td>0</td>\n",
       "      <td>1.868477</td>\n",
       "      <td>0.634091</td>\n",
       "      <td>0.000342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14821</th>\n",
       "      <td>16</td>\n",
       "      <td>869</td>\n",
       "      <td>0</td>\n",
       "      <td>1.865690</td>\n",
       "      <td>0.631303</td>\n",
       "      <td>-0.011642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15693</th>\n",
       "      <td>17</td>\n",
       "      <td>869</td>\n",
       "      <td>0</td>\n",
       "      <td>1.872810</td>\n",
       "      <td>0.638424</td>\n",
       "      <td>0.001541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16565</th>\n",
       "      <td>18</td>\n",
       "      <td>869</td>\n",
       "      <td>0</td>\n",
       "      <td>1.869437</td>\n",
       "      <td>0.635050</td>\n",
       "      <td>-0.007318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17437</th>\n",
       "      <td>19</td>\n",
       "      <td>869</td>\n",
       "      <td>0</td>\n",
       "      <td>1.863425</td>\n",
       "      <td>0.629038</td>\n",
       "      <td>0.002182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loo_guid  test_guid  label      loss  loss_diff   if_diff\n",
       "869           0        869      0  1.888133   0.653746 -0.001626\n",
       "1741          1        869      0  1.888622   0.654235 -0.001123\n",
       "2613          2        869      0  1.888152   0.653765  0.000207\n",
       "3485          3        869      0  1.863295   0.628909 -0.017191\n",
       "4357          4        869      0  1.866936   0.632549 -0.001228\n",
       "5229          5        869      0  1.867203   0.632817 -0.004064\n",
       "6101          6        869      0  1.865716   0.631330  0.000959\n",
       "6973          7        869      0  1.865781   0.631395  0.005427\n",
       "7845          8        869      0  1.864583   0.630196 -0.002895\n",
       "8717          9        869      0  1.868037   0.633650  0.018015\n",
       "9589         10        869      0  1.871785   0.637399 -0.004448\n",
       "10461        11        869      0  1.873724   0.639338 -0.000542\n",
       "11333        12        869      0  1.872625   0.638238 -0.007426\n",
       "12205        13        869      0  1.868625   0.634238 -0.003394\n",
       "13077        14        869      0  1.866474   0.632087 -0.010099\n",
       "13949        15        869      0  1.868477   0.634091  0.000342\n",
       "14821        16        869      0  1.865690   0.631303 -0.011642\n",
       "15693        17        869      0  1.872810   0.638424  0.001541\n",
       "16565        18        869      0  1.869437   0.635050 -0.007318\n",
       "17437        19        869      0  1.863425   0.629038  0.002182"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_guid = 869\n",
    "\n",
    "ldf = pd.read_csv(\"loo_10k/all_loo_losses.csv\")\n",
    "ldf = ldf[ldf.test_guid == test_guid]\n",
    "ldf[\"loss_diff\"] = ldf[\"loss\"] - fdf[fdf.test_guid == test_guid].loss.squeeze()\n",
    "ldf[\"if_diff\"] = (-100.0 / len(train_dataset)) * infl[:20]\n",
    "ldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e7846573-d160-4d5a-a687-f6092d322b80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T02:21:29.280040Z",
     "iopub.status.busy": "2023-05-02T02:21:29.279811Z",
     "iopub.status.idle": "2023-05-02T02:21:29.308933Z",
     "shell.execute_reply": "2023-05-02T02:21:29.308171Z",
     "shell.execute_reply.started": "2023-05-02T02:21:29.280025Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           loss_diff  if_diff\n",
      "loss_diff        1.0      1.0\n",
      "if_diff          1.0      1.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss_diff</th>\n",
       "      <th>if_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>-0.033466</td>\n",
       "      <td>-0.001626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>-0.026826</td>\n",
       "      <td>-0.001123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     loss_diff   if_diff\n",
       "869  -0.033466 -0.001626\n",
       "869  -0.026826 -0.001123"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(ldf[[\"loss_diff\", \"if_diff\"]].corr())\n",
    "ldf[[\"loss_diff\", \"if_diff\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d3149b-3d8b-4627-84f0-b825c49d2499",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eab7de8-a6c1-4f48-8c8e-50c5b4c8a94d",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-02T02:13:31.747516Z",
     "iopub.status.idle": "2023-05-02T02:13:31.747739Z",
     "shell.execute_reply": "2023-05-02T02:13:31.747648Z",
     "shell.execute_reply.started": "2023-05-02T02:13:31.747638Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cdf[[\"loss_diff\", \"if_diff\"]].plot.scatter(\"loss_diff\", \"if_diff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e94f20-adc5-4899-88fa-be0700d7e4c6",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-02T02:13:31.748637Z",
     "iopub.status.idle": "2023-05-02T02:13:31.748836Z",
     "shell.execute_reply": "2023-05-02T02:13:31.748747Z",
     "shell.execute_reply.started": "2023-05-02T02:13:31.748737Z"
    }
   },
   "outputs": [],
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5604e1-ad4c-48f5-8c1b-118734fe5690",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-02T02:13:31.749855Z",
     "iopub.status.idle": "2023-05-02T02:13:31.750053Z",
     "shell.execute_reply": "2023-05-02T02:13:31.749966Z",
     "shell.execute_reply.started": "2023-05-02T02:13:31.749956Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "influences[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4747a947-4024-4bfd-b034-ee51d715e841",
   "metadata": {},
   "source": [
    "## LOO Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed3a10b-6486-4a08-af2c-8d41fbe093ba",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-02T02:13:31.751346Z",
     "iopub.status.idle": "2023-05-02T02:13:31.751571Z",
     "shell.execute_reply": "2023-05-02T02:13:31.751465Z",
     "shell.execute_reply.started": "2023-05-02T02:13:31.751455Z"
    }
   },
   "outputs": [],
   "source": [
    "loo_guid = 0\n",
    "\n",
    "# Create train dataset\n",
    "loo_dataset = create_loo_dataset(train_dataset, loo_guid)\n",
    "train_dataloader = DataLoader(\n",
    "    loo_dataset, batch_size=config[\"batch_size\"], shuffle=True\n",
    ")\n",
    "\n",
    "# Create classifcation model\n",
    "model = BertClassifier.create_bert_classifier(\n",
    "    config[\"bert_model_name\"],\n",
    "    classifier_type=config[\"classifier_type\"],\n",
    "    classifier_hidden_size=config[\"classifier_hidden_size\"],\n",
    "    classifier_drop_out=config[\"classifier_drop_out\"],\n",
    "    freeze_bert=True,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "optimizer = Adam(model.classifier.parameters(), lr=config[\"learning_rate\"])\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "run = wandb.init(project=\"LOO-test\", tags=[\"loo\"], config=config)\n",
    "\n",
    "timings = utils.train(\n",
    "    config=config,\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    loss_fn=loss_fn,\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloader=None,\n",
    ")\n",
    "\n",
    "test_loss, test_acc = utils.evaluate(model, test_dataloader)\n",
    "wandb.summary[\"test/loss\"] = test_loss\n",
    "wandb.summary[\"test/accuracy\"] = test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f2901f-2190-46f5-bedb-f01930b3f66d",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-02T02:13:31.752513Z",
     "iopub.status.idle": "2023-05-02T02:13:31.752812Z",
     "shell.execute_reply": "2023-05-02T02:13:31.752705Z",
     "shell.execute_reply.started": "2023-05-02T02:13:31.752693Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compute loss for each test point\n",
    "df = utils.evaluate_loss_df(model, test_dataloader)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655ef4d8-cae1-418c-88e7-8db35481ddbf",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-02T02:13:31.754212Z",
     "iopub.status.idle": "2023-05-02T02:13:31.754611Z",
     "shell.execute_reply": "2023-05-02T02:13:31.754476Z",
     "shell.execute_reply.started": "2023-05-02T02:13:31.754463Z"
    }
   },
   "outputs": [],
   "source": [
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52099f1-4c5e-4755-9faf-6dd25327f898",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-02T02:13:31.755759Z",
     "iopub.status.idle": "2023-05-02T02:13:31.755975Z",
     "shell.execute_reply": "2023-05-02T02:13:31.755884Z",
     "shell.execute_reply.started": "2023-05-02T02:13:31.755874Z"
    }
   },
   "outputs": [],
   "source": [
    "dfs = []\n",
    "\n",
    "for loo_guid in tqdm(range(2000)):\n",
    "    df = df.drop([c for c in df.columns if \"Unnamed\" in c], axis=1)\n",
    "    df = df.rename(columns={\"guid\": \"test_guid\"})\n",
    "    df[\"loo_guid\"] = loo_guid\n",
    "    df = df[[\"loo_guid\", \"test_guid\", \"loss\", \"label\"]]\n",
    "    dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c1678b-8f2a-4678-8b36-a42164babd7a",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-02T02:13:31.756844Z",
     "iopub.status.idle": "2023-05-02T02:13:31.757066Z",
     "shell.execute_reply": "2023-05-02T02:13:31.756975Z",
     "shell.execute_reply.started": "2023-05-02T02:13:31.756965Z"
    }
   },
   "outputs": [],
   "source": [
    "d = pd.concat(dfs)\n",
    "df = pd.read_csv(\"loo/all_loo_losses.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14c23b1-55d1-411d-a469-ab0dfebae97e",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-02T02:13:31.758176Z",
     "iopub.status.idle": "2023-05-02T02:13:31.758384Z",
     "shell.execute_reply": "2023-05-02T02:13:31.758293Z",
     "shell.execute_reply.started": "2023-05-02T02:13:31.758284Z"
    }
   },
   "outputs": [],
   "source": [
    "d.to_csv(\"loo/all_loo_losses.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fdfa8e-5960-4baa-bde4-4024a621e049",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-02T02:13:31.759362Z",
     "iopub.status.idle": "2023-05-02T02:13:31.759595Z",
     "shell.execute_reply": "2023-05-02T02:13:31.759481Z",
     "shell.execute_reply.started": "2023-05-02T02:13:31.759471Z"
    }
   },
   "outputs": [],
   "source": [
    "test_guid = 4\n",
    "\n",
    "for test_guid in range(800):\n",
    "    min_loss = df[df.test_guid == test_guid].loss.min()\n",
    "    max_loss = df[df.test_guid == test_guid].loss.max()\n",
    "    if min_loss != max_loss:\n",
    "        print(min_loss, max_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4310564a-ecf4-46d5-9487-5811fb3330c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa363b13-6111-47c5-957f-b51cfbb5fec4",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-02T02:13:31.760193Z",
     "iopub.status.idle": "2023-05-02T02:13:31.760395Z",
     "shell.execute_reply": "2023-05-02T02:13:31.760306Z",
     "shell.execute_reply.started": "2023-05-02T02:13:31.760296Z"
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d108a97-58f3-4477-b10a-4cf74161e73c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ba4d86-d06c-4df7-9a07-57d03ee249ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
