{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9be097dd-0cc3-45f3-b665-a8ef93ad83db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-07T03:15:22.058015Z",
     "iopub.status.busy": "2023-05-07T03:15:22.057856Z",
     "iopub.status.idle": "2023-05-07T03:15:22.075542Z",
     "shell.execute_reply": "2023-05-07T03:15:22.074876Z",
     "shell.execute_reply.started": "2023-05-07T03:15:22.057999Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "\n",
    "# os.environ[\"WANDB_SILENT\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d962785-65b7-4e44-8c74-a114a8faa825",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-07T03:15:22.077639Z",
     "iopub.status.busy": "2023-05-07T03:15:22.077432Z",
     "iopub.status.idle": "2023-05-07T03:15:25.345745Z",
     "shell.execute_reply": "2023-05-07T03:15:25.344908Z",
     "shell.execute_reply.started": "2023-05-07T03:15:22.077624Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 14311.86it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 872/872 [00:00<00:00, 10798.86it/s]\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import statistics\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import yaml\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "import wandb\n",
    "from src import BertClassifier\n",
    "from src import datasets as data_utils\n",
    "from src import influence as inf_utils\n",
    "from src import train_utils, utils\n",
    "from src.datasets import create_loo_dataset, create_test_sst2, create_train_sst2\n",
    "\n",
    "device = utils.get_device()\n",
    "\n",
    "config = utils.load_config(\n",
    "    \"model_params/bert_classifier.yaml\", epochs=5, num_training_examples=1000\n",
    ")\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = create_train_sst2(\n",
    "    num_samples=config[\"num_training_examples\"],\n",
    "    tokenizer_name=config[\"bert_model_name\"],\n",
    "    max_seq_len=config[\"max_sequence_length\"],\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "test_dataset = create_test_sst2(\n",
    "    tokenizer_name=config[\"bert_model_name\"],\n",
    "    max_seq_len=config[\"max_sequence_length\"],\n",
    "    device=device,\n",
    ")\n",
    "test_dataloader = DataLoader(test_dataset, shuffle=False, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "57ddb505-c678-4bac-90e2-e4f717d4e334",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-07T03:31:35.631309Z",
     "iopub.status.busy": "2023-05-07T03:31:35.630721Z",
     "iopub.status.idle": "2023-05-07T03:33:48.520832Z",
     "shell.execute_reply": "2023-05-07T03:33:48.519761Z",
     "shell.execute_reply.started": "2023-05-07T03:31:35.631291Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 9523.94it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 872/872 [00:00<00:00, 10563.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LiSSA reps: 2 and num_iterations: 1000\n",
      "Recursion at depth 0: norm is 0.674420\n",
      "Recursion at depth 200: norm is 11.000627\n",
      "Recursion at depth 400: norm is 14.677641\n",
      "Recursion at depth 600: norm is 15.936044\n",
      "Recursion at depth 800: norm is 16.382391\n",
      "Recursion at depth 999: norm is 16.561853\n",
      "Recursion at depth 0: norm is 0.658539\n",
      "Recursion at depth 200: norm is 10.982577\n",
      "Recursion at depth 400: norm is 14.674032\n",
      "Recursion at depth 600: norm is 15.948548\n",
      "Recursion at depth 800: norm is 16.419153\n",
      "Recursion at depth 999: norm is 16.566097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:07<00:00, 136.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LiSSA reps: 2 and num_iterations: 1000\n",
      "Recursion at depth 0: norm is 2.898361\n",
      "Recursion at depth 200: norm is 48.623352\n",
      "Recursion at depth 400: norm is 64.839676\n",
      "Recursion at depth 600: norm is 69.729927\n",
      "Recursion at depth 800: norm is 71.471901\n",
      "Recursion at depth 999: norm is 72.188927\n",
      "Recursion at depth 0: norm is 2.738004\n",
      "Recursion at depth 200: norm is 48.691811\n",
      "Recursion at depth 400: norm is 64.725838\n",
      "Recursion at depth 600: norm is 69.571373\n",
      "Recursion at depth 800: norm is 71.711586\n",
      "Recursion at depth 999: norm is 72.354538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:06<00:00, 144.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LiSSA reps: 2 and num_iterations: 1000\n",
      "Recursion at depth 0: norm is 0.487176\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 37\u001b[0m\n\u001b[1;32m     35\u001b[0m influences \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m test_guid \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m872\u001b[39m):\n\u001b[0;32m---> 37\u001b[0m     infl \u001b[38;5;241m=\u001b[39m \u001b[43minf_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_influence\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfull_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest_guid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_guid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparam_influence\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparam_infl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlissa_r\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlissa_depth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdamping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5e-3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m        \u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data\u001b[38;5;241m=\u001b[39minfl, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(infl)), columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minfluence\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     49\u001b[0m     df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mrename_axis(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_guid\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mreset_index()\n",
      "File \u001b[0;32m~/sentiment-influence-function/src/influence.py:143\u001b[0m, in \u001b[0;36mcompute_influence\u001b[0;34m(full_model, test_guid, param_influence, train_dataset, test_dataset, training_indices, use_bert_embeddings, lissa_r, lissa_depth, damping, scale)\u001b[0m\n\u001b[1;32m    140\u001b[0m t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(train_dataloader) \u001b[38;5;241m*\u001b[39m lissa_depth)\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLiSSA reps: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlissa_r\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and num_iterations: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 143\u001b[0m inverse_hvp \u001b[38;5;241m=\u001b[39m \u001b[43mget_inverse_hvp_lissa\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_grads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfull_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparam_influence\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloader_lissa\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdamping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdamping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlissa_r\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrecursion_depth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_bert_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_bert_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train_guid, train_input_id, train_input_mask, train_label \u001b[38;5;129;01min\u001b[39;00m tqdm(\n\u001b[1;32m    157\u001b[0m     train_dataloader\n\u001b[1;32m    158\u001b[0m ):\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m training_indices \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m train_guid \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m training_indices:\n",
      "File \u001b[0;32m~/sentiment-influence-function/src/influence.py:71\u001b[0m, in \u001b[0;36mget_inverse_hvp_lissa\u001b[0;34m(v, model, device, param_influence, train_loader, damping, num_samples, recursion_depth, scale, use_bert_embeddings)\u001b[0m\n\u001b[1;32m     68\u001b[0m label_ids \u001b[38;5;241m=\u001b[39m label_ids\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     69\u001b[0m model\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 71\u001b[0m model_output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_bert_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_bert_embeddings\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m loss_fn(model_output, label_ids)\n\u001b[1;32m     76\u001b[0m hvp \u001b[38;5;241m=\u001b[39m hv(train_loss, param_influence, cur_estimate)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/sentiment-influence-function/src/BertClassifier.py:110\u001b[0m, in \u001b[0;36mBertClassifier.forward\u001b[0;34m(self, inputs, attention_mask, use_bert_embeddings)\u001b[0m\n\u001b[1;32m    108\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbert(inputs_embeds\u001b[38;5;241m=\u001b[39minputs, attention_mask\u001b[38;5;241m=\u001b[39mattention_mask)\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 110\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m last_hidden_state \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m][:, \u001b[38;5;241m0\u001b[39m, :]\n\u001b[1;32m    113\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(last_hidden_state)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.10/site-packages/transformers/models/distilbert/modeling_distilbert.py:583\u001b[0m, in \u001b[0;36mDistilBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    579\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    581\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(input_ids, inputs_embeds)  \u001b[38;5;66;03m# (bs, seq_length, dim)\u001b[39;00m\n\u001b[0;32m--> 583\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    584\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    585\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    586\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    587\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    590\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.10/site-packages/transformers/models/distilbert/modeling_distilbert.py:359\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, x, attn_mask, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states:\n\u001b[1;32m    357\u001b[0m     all_hidden_states \u001b[38;5;241m=\u001b[39m all_hidden_states \u001b[38;5;241m+\u001b[39m (hidden_state,)\n\u001b[0;32m--> 359\u001b[0m layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    362\u001b[0m hidden_state \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    364\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.10/site-packages/transformers/models/distilbert/modeling_distilbert.py:295\u001b[0m, in \u001b[0;36mTransformerBlock.forward\u001b[0;34m(self, x, attn_mask, head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;124;03mParameters:\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;124;03m    x: torch.tensor(bs, seq_length, dim)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;124;03m    torch.tensor(bs, seq_length, dim) The output of the transformer block contextualization.\u001b[39;00m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;66;03m# Self-Attention\u001b[39;00m\n\u001b[0;32m--> 295\u001b[0m sa_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n\u001b[1;32m    304\u001b[0m     sa_output, sa_weights \u001b[38;5;241m=\u001b[39m sa_output  \u001b[38;5;66;03m# (bs, seq_length, dim), (bs, n_heads, seq_length, seq_length)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.10/site-packages/transformers/models/distilbert/modeling_distilbert.py:222\u001b[0m, in \u001b[0;36mMultiHeadSelfAttention.forward\u001b[0;34m(self, query, key, value, mask, head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    220\u001b[0m scores \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(q, k\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m))  \u001b[38;5;66;03m# (bs, n_heads, q_length, k_length)\u001b[39;00m\n\u001b[1;32m    221\u001b[0m mask \u001b[38;5;241m=\u001b[39m (mask \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mview(mask_reshp)\u001b[38;5;241m.\u001b[39mexpand_as(scores)  \u001b[38;5;66;03m# (bs, n_heads, q_length, k_length)\u001b[39;00m\n\u001b[0;32m--> 222\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mscores\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmasked_fill\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscores\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmin\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (bs, n_heads, q_length, k_length)\u001b[39;00m\n\u001b[1;32m    226\u001b[0m weights \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39msoftmax(scores, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# (bs, n_heads, q_length, k_length)\u001b[39;00m\n\u001b[1;32m    227\u001b[0m weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(weights)  \u001b[38;5;66;03m# (bs, n_heads, q_length, k_length)\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from src import influence as inf_utils\n",
    "from src import train_utils, utils, BertClassifier\n",
    "from src.datasets import (create_loo_dataset, create_test_sst2,\n",
    "                          create_train_sst2)\n",
    "\n",
    "device = utils.get_device()\n",
    "\n",
    "model, config = BertClassifier.load_model(\n",
    "    \"model_params/bert-classifier-epoch5-1000.pt\"\n",
    ")\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = create_train_sst2(\n",
    "    num_samples=config[\"num_training_examples\"],\n",
    "    tokenizer_name=config[\"bert_model_name\"],\n",
    "    max_seq_len=config[\"max_sequence_length\"],\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "test_dataset = create_test_sst2(\n",
    "    tokenizer_name=config[\"bert_model_name\"],\n",
    "    max_seq_len=config[\"max_sequence_length\"],\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "# TODO thread pool\n",
    "\n",
    "param_infl = list(model.classifier.parameters())\n",
    "\n",
    "influences = []\n",
    "for test_guid in range(872):\n",
    "    infl = inf_utils.compute_influence(\n",
    "        full_model=model,\n",
    "        test_guid=test_guid,\n",
    "        param_influence=param_infl,\n",
    "        train_dataset=train_dataset,\n",
    "        test_dataset=test_dataset,\n",
    "        lissa_r=2,\n",
    "        lissa_depth=1,\n",
    "        damping=5e-3,\n",
    "        scale=100,        \n",
    "    )\n",
    "    df = pd.DataFrame(data=infl, index=range(len(infl)), columns=['influence'])\n",
    "    df = df.rename_axis('train_guid').reset_index()\n",
    "    df['test_guid'] = test_guid\n",
    "    df.to_csv(f\"{output_dir}/influence-testguid-{test_guid}\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c6026791-0989-423c-9201-dcf5fee2034e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-07T03:34:55.536819Z",
     "iopub.status.busy": "2023-05-07T03:34:55.536117Z",
     "iopub.status.idle": "2023-05-07T03:34:55.563142Z",
     "shell.execute_reply": "2023-05-07T03:34:55.562385Z",
     "shell.execute_reply.started": "2023-05-07T03:34:55.536800Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_guid</th>\n",
       "      <th>influence</th>\n",
       "      <th>test_guid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.114924</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_guid  influence  test_guid\n",
       "0           0   0.000415          0\n",
       "0           0   0.114924          1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = pd.concat(influences)\n",
    "d[d['train_guid'] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5f0a57-22fe-45ec-b0be-dd685a0ae0b0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train Model on Full Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "650bbd48-baaa-4cdf-b941-a9b3cdc64d33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-07T03:15:25.346500Z",
     "iopub.status.busy": "2023-05-07T03:15:25.346319Z",
     "iopub.status.idle": "2023-05-07T03:15:51.899055Z",
     "shell.execute_reply": "2023-05-07T03:15:51.898260Z",
     "shell.execute_reply.started": "2023-05-07T03:15:25.346485Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpatcao\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/pcao/sentiment-influence-function/wandb/run-20230506_231526-dn0g2ek9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/patcao/Bert-scratch/runs/dn0g2ek9' target=\"_blank\">fluent-wildflower-103</a></strong> to <a href='https://wandb.ai/patcao/Bert-scratch' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/patcao/Bert-scratch' target=\"_blank\">https://wandb.ai/patcao/Bert-scratch</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/patcao/Bert-scratch/runs/dn0g2ek9' target=\"_blank\">https://wandb.ai/patcao/Bert-scratch/runs/dn0g2ek9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 25.43batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 30.30batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 29.48batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 29.63batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 29.72batch/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12260fc77cc846e79b4625d597dd6a73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.003 MB of 0.003 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>train/accuracy</td><td>▁▆███</td></tr><tr><td>train/batch_loss</td><td>▆▇▆█▅▅▄▅▄▄▄▃▄▄▃▂▃▃▄▆▄▂▂▄▃▃▁▄▁▂▄▁▅▁▅▃▃▂▃▅</td></tr><tr><td>train/loss</td><td>█▄▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>test/accuracy</td><td>80.27523</td></tr><tr><td>test/loss</td><td>0.41442</td></tr><tr><td>train/accuracy</td><td>85.21825</td></tr><tr><td>train/batch_loss</td><td>0.13145</td></tr><tr><td>train/loss</td><td>0.36353</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fluent-wildflower-103</strong> at: <a href='https://wandb.ai/patcao/Bert-scratch/runs/dn0g2ek9' target=\"_blank\">https://wandb.ai/patcao/Bert-scratch/runs/dn0g2ek9</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230506_231526-dn0g2ek9/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "full_model, fdf, full_test_loss, full_test_acc = train_utils.train_bert_model(\n",
    "    train_dataset, test_dataset, config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d32cb9a3-272f-4db8-b56b-4af5c65ed231",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-07T03:17:01.801544Z",
     "iopub.status.busy": "2023-05-07T03:17:01.801073Z",
     "iopub.status.idle": "2023-05-07T03:17:08.152062Z",
     "shell.execute_reply": "2023-05-07T03:17:08.151327Z",
     "shell.execute_reply.started": "2023-05-07T03:17:01.801527Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(     test_guid                     logits  pred  label      loss\n",
       " 0            0     [-2.065672, 1.6855112]     1      1  0.023218\n",
       " 1            1     [1.207626, -1.0739517]     0      0  0.097238\n",
       " 2            2     [-2.231233, 1.8515978]     1      1  0.016719\n",
       " 3            3    [-1.3567762, 1.1909542]     1      1  0.075348\n",
       " 4            4  [0.46830642, -0.72701955]     0      0  0.264366\n",
       " ..         ...                        ...   ...    ...       ...\n",
       " 867        867    [-0.9934867, 0.8819245]     1      0  2.018032\n",
       " 868        868  [-0.49477586, 0.55733645]     1      1  0.299511\n",
       " 869        869   [-0.8512296, 0.39946464]     1      0  1.502469\n",
       " 870        870  [-0.0993969, -0.13528356]     0      0  0.675365\n",
       " 871        871    [-1.6719589, 1.1752533]     1      1  0.056386\n",
       " \n",
       " [872 rows x 5 columns],\n",
       " 0.41442395658465236,\n",
       " 80.27522935779817)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, config = BertClassifier.load_model(\n",
    "    \"model_params/bert-classifier-epoch5-1000.pt\"\n",
    ")\n",
    "\n",
    "df, loss, acc = train_utils.evaluate_loss(model, test_dataloader)\n",
    "df, loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf3c6a41-1626-4450-ba80-3069002d9f83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-07T03:15:58.025376Z",
     "iopub.status.busy": "2023-05-07T03:15:58.025205Z",
     "iopub.status.idle": "2023-05-07T03:15:58.048320Z",
     "shell.execute_reply": "2023-05-07T03:15:58.046612Z",
     "shell.execute_reply.started": "2023-05-07T03:15:58.025361Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (476313318.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[6], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    -\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954614d0-0807-4bf4-9e62-3f9b3ab6fe48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690fe2ca-3131-4b0e-9945-dcdf8bc61778",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T03:15:58.048950Z",
     "iopub.status.idle": "2023-05-07T03:15:58.049203Z",
     "shell.execute_reply": "2023-05-07T03:15:58.049099Z",
     "shell.execute_reply.started": "2023-05-07T03:15:58.049088Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create Bert model\n",
    "model = BertClassifier.create_bert_classifier(\n",
    "    config[\"bert_model_name\"],\n",
    "    classifier_type=config[\"classifier_type\"],\n",
    "    classifier_hidden_size=config[\"classifier_hidden_size\"],\n",
    "    classifier_drop_out=config[\"classifier_drop_out\"],\n",
    "    classifier_init_state_path=config[\"classifier_init_state_path\"],\n",
    "    freeze_bert=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608fbed1-9ade-448b-8d2b-d9235db3451a",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T03:15:58.050371Z",
     "iopub.status.idle": "2023-05-07T03:15:58.050663Z",
     "shell.execute_reply": "2023-05-07T03:15:58.050554Z",
     "shell.execute_reply.started": "2023-05-07T03:15:58.050542Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TEST_GUID = 716\n",
    "\n",
    "fdf[fdf.test_guid == TEST_GUID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d435fb-74d4-4193-8000-71749a28b901",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T03:15:58.051349Z",
     "iopub.status.idle": "2023-05-07T03:15:58.051585Z",
     "shell.execute_reply": "2023-05-07T03:15:58.051482Z",
     "shell.execute_reply.started": "2023-05-07T03:15:58.051472Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.argsort(fdf.loss)[300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15da62fe-c731-46de-8780-022ac964fa0d",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T03:15:58.052449Z",
     "iopub.status.idle": "2023-05-07T03:15:58.052668Z",
     "shell.execute_reply": "2023-05-07T03:15:58.052573Z",
     "shell.execute_reply.started": "2023-05-07T03:15:58.052563Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fdf[fdf.test_guid == 716]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cca28c-b19d-4cde-893d-887da842bc28",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Compute Loss Influence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca428991-0d45-4a12-ba67-0c23e47397cf",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T03:15:58.054012Z",
     "iopub.status.idle": "2023-05-07T03:15:58.054307Z",
     "shell.execute_reply": "2023-05-07T03:15:58.054202Z",
     "shell.execute_reply.started": "2023-05-07T03:15:58.054190Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "param_infl = list(full_model.classifier.parameters())\n",
    "infl = inf_utils.compute_influence(\n",
    "    full_model=full_model,\n",
    "    test_guid=TEST_GUID,\n",
    "    param_influence=param_infl,\n",
    "    train_dataset=train_dataset,\n",
    "    test_dataset=test_dataset,\n",
    "    lissa_r=2,\n",
    "    lissa_depth=1,\n",
    "    damping=5e-3,\n",
    "    scale=100,\n",
    "    # training_indices=list(range(15)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95fa59d-cc88-4b0f-85c8-c47a3ebe9dac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060d36e0-e056-4008-9148-795a9f793cc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e6694f-a128-4d95-9f4a-c53292960192",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bdf78bd2-99f7-46e6-80ed-f3843da52249",
   "metadata": {},
   "source": [
    "## Compute LOO Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bc2f59-6acc-485c-b8ce-af8570a5fb37",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T03:15:58.056236Z",
     "iopub.status.idle": "2023-05-07T03:15:58.056473Z",
     "shell.execute_reply": "2023-05-07T03:15:58.056378Z",
     "shell.execute_reply.started": "2023-05-07T03:15:58.056368Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def centered_percentile_idxs(infl, remove_length):\n",
    "    half = int(len(infl) / 2)\n",
    "    start_index = max(0, half - int(remove_length / 2))\n",
    "    end_index = start_index + remove_length\n",
    "    return np.argsort(infl)[start_index:end_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91002f3-2292-46b5-ae17-b87be3eb2423",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T03:15:58.057562Z",
     "iopub.status.idle": "2023-05-07T03:15:58.057803Z",
     "shell.execute_reply": "2023-05-07T03:15:58.057707Z",
     "shell.execute_reply.started": "2023-05-07T03:15:58.057696Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_loo_sweep(test_guid: int) -> pd.DataFrame:\n",
    "    loo_dfs = []\n",
    "    # np.arange(0.05, 0.8, 0.05)\n",
    "    for remove_pct in [0.1]:\n",
    "        remove_length = int(remove_pct * len(train_dataset))\n",
    "\n",
    "        # Remove random indices\n",
    "        remove_idxs = np.random.randint(\n",
    "            low=0, high=len(train_dataset), size=remove_length\n",
    "        )\n",
    "        loo_dataset = create_loo_dataset(train_dataset, remove_idxs)\n",
    "        _, rdf, rad_test_loss, rand_test_acc = train_utils.train_bert_model(\n",
    "            loo_dataset,\n",
    "            test_dataset,\n",
    "            config,\n",
    "        )\n",
    "        rdf[\"type\"] = \"rand\"\n",
    "\n",
    "        # Remove top influence score\n",
    "        remove_idxs = np.argsort(-infl)[:remove_length]\n",
    "        loo_dataset = create_loo_dataset(train_dataset, remove_idxs)\n",
    "        _, tdf, rad_test_loss, rand_test_acc = train_utils.train_bert_model(\n",
    "            loo_dataset, test_dataset, config\n",
    "        )\n",
    "        tdf[\"type\"] = \"top\"\n",
    "\n",
    "        # Remove bottom influence score\n",
    "        remove_idxs = np.argsort(infl)[:remove_length]\n",
    "        loo_dataset = create_loo_dataset(train_dataset, remove_idxs)\n",
    "        _, bdf, rad_test_loss, rand_test_acc = train_utils.train_bert_model(\n",
    "            loo_dataset, test_dataset, config\n",
    "        )\n",
    "        bdf[\"type\"] = \"bot\"\n",
    "\n",
    "        # Remove near 0 influence score\n",
    "        remove_idxs = centered_percentile_idxs(infl, remove_length)\n",
    "        loo_dataset = create_loo_dataset(train_dataset, remove_idxs)\n",
    "        _, zdf, rad_test_loss, rand_test_acc = train_utils.train_bert_model(\n",
    "            loo_dataset, test_dataset, config\n",
    "        )\n",
    "        zdf[\"type\"] = \"zero\"\n",
    "\n",
    "        df = pd.concat([rdf, tdf, bdf, zdf], axis=0)\n",
    "        df[\"remove_pct\"] = remove_pct\n",
    "\n",
    "        loo_dfs.append(df)\n",
    "    return pd.concat(loo_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beaf4249-4144-40ba-ad32-0c644d455061",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T03:15:58.058932Z",
     "iopub.status.idle": "2023-05-07T03:15:58.059145Z",
     "shell.execute_reply": "2023-05-07T03:15:58.059054Z",
     "shell.execute_reply.started": "2023-05-07T03:15:58.059045Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = compute_loo_sweep(716)\n",
    "# df.to_csv('loo_dfs_0.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5038aab-b05a-4fb6-bcaa-b4c704941088",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T03:15:58.059980Z",
     "iopub.status.idle": "2023-05-07T03:15:58.060206Z",
     "shell.execute_reply": "2023-05-07T03:15:58.060114Z",
     "shell.execute_reply.started": "2023-05-07T03:15:58.060104Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[(df.type == \"rand\") & (df.test_guid == TEST_GUID)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f28cb44-ef2e-48db-875f-4dc3efbf0caf",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T03:15:58.061190Z",
     "iopub.status.idle": "2023-05-07T03:15:58.061422Z",
     "shell.execute_reply": "2023-05-07T03:15:58.061325Z",
     "shell.execute_reply.started": "2023-05-07T03:15:58.061315Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[(df.type == \"top\") & (df.test_guid == TEST_GUID)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1be2de-ca2f-4459-8ce3-bdc90a9dc12b",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T03:15:58.062842Z",
     "iopub.status.idle": "2023-05-07T03:15:58.063103Z",
     "shell.execute_reply": "2023-05-07T03:15:58.062979Z",
     "shell.execute_reply.started": "2023-05-07T03:15:58.062969Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[(df.type == \"bot\") & (df.test_guid == TEST_GUID)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9151c7-eb45-4098-b020-74610a7f3343",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T03:15:58.064442Z",
     "iopub.status.idle": "2023-05-07T03:15:58.064739Z",
     "shell.execute_reply": "2023-05-07T03:15:58.064627Z",
     "shell.execute_reply.started": "2023-05-07T03:15:58.064615Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[(df.type == \"zero\") & (df.test_guid == TEST_GUID)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819946d9-9fc6-4b0c-88d0-b4d707a60319",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe1934c-e49d-46d3-b3c5-977552813ad5",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T03:15:58.065567Z",
     "iopub.status.idle": "2023-05-07T03:15:58.065803Z",
     "shell.execute_reply": "2023-05-07T03:15:58.065705Z",
     "shell.execute_reply.started": "2023-05-07T03:15:58.065696Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TEST_GUID = 716\n",
    "base_line_loss = fdf[fdf.test_guid == TEST_GUID].loss.squeeze()\n",
    "\n",
    "rand = df[(df.type == \"rand\") & (df.test_guid == TEST_GUID)]\n",
    "rand = rand[[\"remove_pct\", \"loss\"]]\n",
    "\n",
    "zero = df[(df.type == \"zero\") & (df.test_guid == TEST_GUID)]\n",
    "zero = zero[[\"remove_pct\", \"loss\"]]\n",
    "\n",
    "top = df[(df.type == \"top\") & (df.test_guid == TEST_GUID)]\n",
    "top = top[[\"remove_pct\", \"loss\"]]\n",
    "\n",
    "bot = df[(df.type == \"bot\") & (df.test_guid == TEST_GUID)]\n",
    "bot = bot[[\"remove_pct\", \"loss\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c644d600-7203-48af-b7a2-21d3f464d9e8",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T03:15:58.067661Z",
     "iopub.status.idle": "2023-05-07T03:15:58.068151Z",
     "shell.execute_reply": "2023-05-07T03:15:58.067966Z",
     "shell.execute_reply.started": "2023-05-07T03:15:58.067940Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_line_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa64652e-cb44-4c8c-9be8-63df3f2477c0",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T03:15:58.070229Z",
     "iopub.status.idle": "2023-05-07T03:15:58.070796Z",
     "shell.execute_reply": "2023-05-07T03:15:58.070572Z",
     "shell.execute_reply.started": "2023-05-07T03:15:58.070550Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(rand.remove_pct, rand.loss, \"g-\")\n",
    "plt.plot(zero.remove_pct, zero.loss, \"g--\")\n",
    "\n",
    "# plt.plot(top.remove_pct, top.loss, 'r-')\n",
    "plt.plot(bot.remove_pct, bot.loss, \"b-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ecfcb9-fe20-443e-ab9f-2cb107575a9e",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T03:15:58.072943Z",
     "iopub.status.idle": "2023-05-07T03:15:58.073407Z",
     "shell.execute_reply": "2023-05-07T03:15:58.073214Z",
     "shell.execute_reply.started": "2023-05-07T03:15:58.073195Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rand"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9024f66-e68d-4309-bcd1-c3a7dce56e6c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Remove Random 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe4f34f-fd42-441b-806c-104b10d6d2de",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T03:15:58.075585Z",
     "iopub.status.idle": "2023-05-07T03:15:58.075933Z",
     "shell.execute_reply": "2023-05-07T03:15:58.075789Z",
     "shell.execute_reply.started": "2023-05-07T03:15:58.075776Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "remove_pct = 0.1\n",
    "\n",
    "\n",
    "remove_length = int(remove_pct * len(train_dataset))\n",
    "\n",
    "\n",
    "remove_idxs = np.random.randint(low=0, high=max_idx, size=num_indices)\n",
    "loo_dataset = create_loo_dataset(train_dataset, remove_idxs)\n",
    "\n",
    "rand_model, rdf, rad_test_loss, rand_test_acc = train_model(\n",
    "    loo_dataset, test_dataset, config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8eb9dc-2007-418a-9d8e-e7427042b51e",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T03:15:58.076480Z",
     "iopub.status.idle": "2023-05-07T03:15:58.076714Z",
     "shell.execute_reply": "2023-05-07T03:15:58.076615Z",
     "shell.execute_reply.started": "2023-05-07T03:15:58.076605Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rdf[rdf.test_guid == TEST_GUID]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0493a03f-6dd2-418f-8139-b74e2518610c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Remove Top 10% Influences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa006764-2a85-4d73-bd08-668523c99d39",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T03:15:58.077754Z",
     "iopub.status.idle": "2023-05-07T03:15:58.078054Z",
     "shell.execute_reply": "2023-05-07T03:15:58.077950Z",
     "shell.execute_reply.started": "2023-05-07T03:15:58.077931Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "remove_pct = 0.1\n",
    "remove_length = int(remove_pct * len(train_dataset))\n",
    "\n",
    "top_indxs = np.argsort(-infl)[:remove_length]\n",
    "loo_dataset = create_loo_dataset(train_dataset, top_indxs)\n",
    "\n",
    "t_model, tdf, top_test_loss, top_test_acc = train_model(\n",
    "    loo_dataset, test_dataset, config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66795a5-9761-4015-a1e7-d78f29981338",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T03:15:58.079409Z",
     "iopub.status.idle": "2023-05-07T03:15:58.079699Z",
     "shell.execute_reply": "2023-05-07T03:15:58.079593Z",
     "shell.execute_reply.started": "2023-05-07T03:15:58.079582Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tdf[tdf.test_guid == TEST_GUID]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eefaafc-4830-4852-aa33-a6e06c25c0f1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Remove Bottom 10% Influences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa1a6ad-72af-4424-be7f-ec73084189ef",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T03:15:58.081117Z",
     "iopub.status.idle": "2023-05-07T03:15:58.081498Z",
     "shell.execute_reply": "2023-05-07T03:15:58.081337Z",
     "shell.execute_reply.started": "2023-05-07T03:15:58.081321Z"
    }
   },
   "outputs": [],
   "source": [
    "remove_pct = 0.1\n",
    "remove_length = int(remove_pct * len(train_dataset))\n",
    "\n",
    "top_indxs = np.argsort(infl)[:remove_length]\n",
    "loo_dataset = create_loo_dataset(train_dataset, top_indxs)\n",
    "\n",
    "b_model, bdf, bot_test_loss, bot_test_acc = train_model(\n",
    "    loo_dataset, test_dataset, config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38479db-102a-4140-af57-24847bef82d0",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T03:15:58.082993Z",
     "iopub.status.idle": "2023-05-07T03:15:58.083255Z",
     "shell.execute_reply": "2023-05-07T03:15:58.083151Z",
     "shell.execute_reply.started": "2023-05-07T03:15:58.083140Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fdf[fdf.test_guid == TEST_GUID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddef4be-c49e-4f4a-804e-1c27e6f936c3",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T03:15:58.084449Z",
     "iopub.status.idle": "2023-05-07T03:15:58.084792Z",
     "shell.execute_reply": "2023-05-07T03:15:58.084676Z",
     "shell.execute_reply.started": "2023-05-07T03:15:58.084660Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rdf[rdf.test_guid == TEST_GUID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacbbcec-9a8e-4c90-8456-1bc0651971d3",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T03:15:58.086306Z",
     "iopub.status.idle": "2023-05-07T03:15:58.086529Z",
     "shell.execute_reply": "2023-05-07T03:15:58.086438Z",
     "shell.execute_reply.started": "2023-05-07T03:15:58.086428Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tdf[tdf.test_guid == TEST_GUID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752247ef-4fef-4230-8577-fbdfbc48cf07",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T03:15:58.087318Z",
     "iopub.status.idle": "2023-05-07T03:15:58.087540Z",
     "shell.execute_reply": "2023-05-07T03:15:58.087449Z",
     "shell.execute_reply.started": "2023-05-07T03:15:58.087439Z"
    }
   },
   "outputs": [],
   "source": [
    "bdf[bdf.test_guid == TEST_GUID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55e75ef-98fe-4f5c-9093-0b742c365a06",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T03:15:58.089086Z",
     "iopub.status.idle": "2023-05-07T03:15:58.089489Z",
     "shell.execute_reply": "2023-05-07T03:15:58.089316Z",
     "shell.execute_reply.started": "2023-05-07T03:15:58.089298Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import src.datasets as datasets\n",
    "\n",
    "datasets.get_test_example(TEST_GUID).sentence.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8601b3b4-4df9-4f18-a549-e1e3ab9cf1f5",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T03:15:58.090733Z",
     "iopub.status.idle": "2023-05-07T03:15:58.091057Z",
     "shell.execute_reply": "2023-05-07T03:15:58.090938Z",
     "shell.execute_reply.started": "2023-05-07T03:15:58.090926Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fdf.sort_values(\"loss\", ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
