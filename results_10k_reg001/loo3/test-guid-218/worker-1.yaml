batch_size: 32
bert_model_name: distilbert-base-uncased
classifier_drop_out: 0
classifier_hidden_size: 0
classifier_init_state_path: model_params/bert-epoch9-reg0.001-10000.pt
classifier_type: single-fc
epochs: 3
learning_rate: 1.0e-05
max_sequence_length: 64
num_training_examples: 10000
num_workers: 1
optimizer_weight_decay: 0.001
worker_id: 1
