batch_size: 32
bert_model_name: distilbert-base-uncased
classifier_drop_out: 0
classifier_hidden_size: 0
classifier_init_state_path: model_params/init_classifier_params.pt
classifier_type: single-fc
epochs: 9
learning_rate: 1.0e-05
max_sequence_length: 64
num_training_examples: 10000
num_workers: 100
optimizer_weight_decay: 0.001
worker_id: 30
