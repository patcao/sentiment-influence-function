{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j7TqVDwQqWhv"
   },
   "source": [
    "## Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1679952484280,
     "user": {
      "displayName": "Patrick Cao",
      "userId": "14491048743324317279"
     },
     "user_tz": 240
    },
    "id": "3hV2Ty1MUoI4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import re\n",
    "\n",
    "# from transformers import get_linear_schedule_with_warmup\n",
    "# from transformers.optimization import AdamW\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from sys import platform\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import src.utils as utils\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VudllTu25rd0"
   },
   "source": [
    "## Set up GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1679952484280,
     "user": {
      "displayName": "Patrick Cao",
      "userId": "14491048743324317279"
     },
     "user_tz": 240
    },
    "id": "UUs_V6R55tMV",
    "outputId": "c94b30c5-7bb5-446d-821d-17c0ce1fbbcd",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "Device name: NVIDIA GeForce GTX 1070\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"There are {torch.cuda.device_count()} GPU(s) available.\")\n",
    "    print(\"Device name:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"No GPU available, using the CPU instead.\")\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GZNBtl3OHHvo"
   },
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 218,
     "status": "ok",
     "timestamp": 1679953370279,
     "user": {
      "displayName": "Patrick Cao",
      "userId": "14491048743324317279"
     },
     "user_tz": 240
    },
    "id": "8KFmLDXMGwxy",
    "outputId": "c5bb5c94-a8b3-46fb-d48d-e595f740c978",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 67349\n",
      "test: 1821\n",
      "val: 872\n"
     ]
    }
   ],
   "source": [
    "data_path = Path(\"data\")\n",
    "\n",
    "all_train_df = pd.read_csv(data_path / \"train.csv\")\n",
    "all_test_df = pd.read_csv(data_path / \"test.csv\")\n",
    "all_val_df = pd.read_csv(data_path / \"val.csv\")\n",
    "\n",
    "print(f\"train: {len(all_train_df)}\")\n",
    "print(f\"test: {len(all_test_df)}\")\n",
    "print(f\"val: {len(all_val_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 60614\n",
      "val: 6735\n",
      "test: 872\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, val_df = train_test_split(all_train_df, test_size=0.1, random_state=23)\n",
    "test_df = all_val_df\n",
    "\n",
    "# Reset all indices\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df = val_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "print(f\"train: {len(train_df)}\")\n",
    "print(f\"val: {len(val_df)}\")\n",
    "print(f\"test: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.sentence.apply(lambda d: len(d.split())).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.sentence.apply(lambda d: len(d.split())).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.sentence.apply(lambda d: len(d.split())).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Y4ZecNYK3yr"
   },
   "source": [
    "# Fine-Tuned Bert Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PffVTcgWOSAJ"
   },
   "source": [
    "## PyTorch DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26218,
     "status": "ok",
     "timestamp": 1679953959402,
     "user": {
      "displayName": "Patrick Cao",
      "userId": "14491048743324317279"
     },
     "user_tz": 240
    },
    "id": "PWPl1GoGOSOg",
    "outputId": "f3644dc7-73d4-4e2a-93d1-656b3f6b655d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 60614/60614 [00:04<00:00, 13847.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 6735/6735 [00:00<00:00, 12217.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 872/872 [00:00<00:00, 10408.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.29 s, sys: 490 ms, total: 6.78 s\n",
      "Wall time: 7.05 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from src.datasets import SST2Dataset\n",
    "from torch.utils.data import (\n",
    "    DataLoader,\n",
    "    RandomSampler,\n",
    "    SequentialSampler,\n",
    "    TensorDataset,\n",
    "    random_split,\n",
    ")\n",
    "\n",
    "# For fine-tuning BERT, the authors recommend a batch size of 16 or 32.\n",
    "batch_size = 32\n",
    "MAX_LEN = 64\n",
    "FRAC = 1\n",
    "\n",
    "device = utils.get_device()\n",
    "\n",
    "# Train data\n",
    "print(\"Train\")\n",
    "train_data = SST2Dataset.create_dataset(\n",
    "    \"train\", device, train_df, max_seq_len=MAX_LEN, frac=FRAC\n",
    ")\n",
    "train_dataloader = DataLoader(\n",
    "    train_data, sampler=RandomSampler(train_data), batch_size=batch_size\n",
    ")\n",
    "\n",
    "# Val data\n",
    "print(\"Validation\")\n",
    "val_data = SST2Dataset.create_dataset(\n",
    "    \"val\", device, val_df, max_seq_len=MAX_LEN, frac=FRAC\n",
    ")\n",
    "val_dataloader = DataLoader(val_data, sampler=SequentialSampler(val_data))\n",
    "\n",
    "# Test data\n",
    "print(\"Test\")\n",
    "test_data = SST2Dataset.create_dataset(\"test\", device, test_df, max_seq_len=MAX_LEN)\n",
    "test_dataloader = DataLoader(test_data, sampler=SequentialSampler(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EbClhDGfadbP"
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1679953967309,
     "user": {
      "displayName": "Patrick Cao",
      "userId": "14491048743324317279"
     },
     "user_tz": 240
    },
    "id": "dPVnw-CjOc8C"
   },
   "outputs": [],
   "source": [
    "from src.BertClassifier import BertClassifier\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "\n",
    "def initialize_model(epochs=4):\n",
    "    \"\"\"Initialize the Bert Classifier, the optimizer and the learning rate scheduler.\"\"\"\n",
    "    # Instantiate Bert Classifier\n",
    "    device = utils.get_device()\n",
    "    bert_classifier = BertClassifier(freeze_bert=True)\n",
    "\n",
    "    # Tell PyTorch to run the model on GPU\n",
    "    bert_classifier.to(device)\n",
    "\n",
    "    # Create the optimizer\n",
    "    optimizer = AdamW(\n",
    "        bert_classifier.classifier.parameters(),\n",
    "        lr=5e-5,  # Default learning rate\n",
    "        eps=1e-8,  # Default epsilon value\n",
    "    )\n",
    "\n",
    "    # Total number of training steps\n",
    "    total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "    # Set up the learning rate scheduler\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer, num_warmup_steps=0, num_training_steps=total_steps  # Default value\n",
    "    )\n",
    "    return bert_classifier, optimizer, scheduler\n",
    "\n",
    "def load_model():\n",
    "    device = utils.get_device()\n",
    "    classifier = torch.load(\"classifier\")\n",
    "    # Create the optimizer\n",
    "    optimizer = AdamW(\n",
    "        bert_classifier.classifier.parameters(),\n",
    "        lr=5e-5,  # Default learning rate\n",
    "        eps=1e-8,  # Default epsilon value\n",
    "    )\n",
    "\n",
    "    # Total number of training steps\n",
    "    total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "    # TODO use a different type of scheduler when retraining the model\n",
    "    # Set up the learning rate scheduler\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer, num_warmup_steps=0, num_training_steps=total_steps  # Default value\n",
    "    )\n",
    "    \n",
    "    return classifier, optimizerr, scheduler\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sx_FlsINOdKP"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/home/pcao/miniconda3/envs/pytorch/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 1895/1895 [02:14<00:00, 14.10batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1    |  1894   |   0.526085   |     -      |     -     |  134.42  \n",
      "----------------------------------------------------------------------\n",
      "   1    |    -    |   0.526085   |  0.407122  |   83.30   |  176.31  \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 1895/1895 [02:04<00:00, 15.18batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   2    |  1894   |   0.405027   |     -      |     -     |  124.87  \n",
      "----------------------------------------------------------------------\n",
      "   2    |    -    |   0.405027   |  0.367280  |   84.20   |  165.47  \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 1895/1895 [02:05<00:00, 15.15batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   3    |  1894   |   0.384332   |     -      |     -     |  125.12  \n",
      "----------------------------------------------------------------------\n",
      "   3    |    -    |   0.384332   |  0.355725  |   84.90   |  165.12  \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|████████████████████████████████████████████████████████████████████████▌                     | 1462/1895 [01:35<00:28, 15.34batch/s]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "epochs = 10\n",
    "\n",
    "utils.set_seed(42)  # Set seed for reproducibility\n",
    "bert_classifier, optimizer, scheduler = initialize_model(epochs=epochs)\n",
    "history = utils.train(\n",
    "    bert_classifier,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    train_dataloader,\n",
    "    val_dataloader,\n",
    "    epochs=epochs,\n",
    "    evaluation=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoc_length = len(history[\"train_loss\"])\n",
    "x = np.arange(1, epoc_length + 1)\n",
    "\n",
    "\n",
    "plt.plot(x, history[\"train_loss\"])\n",
    "plt.plot(x, history[\"val_loss\"])\n",
    "plt.title(\"Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(1, len(train_loss) + 1), train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(1, len(val_loss) + 1), val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save model parameters\n",
    "\n",
    "model_params_path = Path(\"model_params\")\n",
    "\n",
    "now = datetime.now().strftime(\"%m-%d-%Y_%H%M%S\")\n",
    "\n",
    "# torch.save(bert_classifier.classifier.state_dict(), model_params_path / f\"{now}-classifier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dUL4jY_DZ9vx"
   },
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from src.BertClassifier import bert_predict\n",
    "from src.utils import evaluate_roc\n",
    "\n",
    "# Compute predicted probabilities on the test set\n",
    "probs = bert_predict(bert_classifier, test_dataloader, device)\n",
    "\n",
    "# Evaluate the Bert classifier\n",
    "# evaluate_roc(probs, y_val[: len(probs)])\n",
    "evaluate_roc(probs, test_data.labels.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 330
    },
    "executionInfo": {
     "elapsed": 3673,
     "status": "ok",
     "timestamp": 1679954495012,
     "user": {
      "displayName": "Patrick Cao",
      "userId": "14491048743324317279"
     },
     "user_tz": 240
    },
    "id": "LShcLRnWZ_H-",
    "outputId": "e918a441-269d-45fe-8d51-2dea238d3e51"
   },
   "outputs": [],
   "source": [
    "# Compute predicted probabilities on the validation set\n",
    "probs = bert_predict(bert_classifier, val_dataloader, device)\n",
    "\n",
    "# Evaluate the Bert classifier\n",
    "evaluate_roc(probs, val_data.labels.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "aborted",
     "timestamp": 1679952551346,
     "user": {
      "displayName": "Patrick Cao",
      "userId": "14491048743324317279"
     },
     "user_tz": 240
    },
    "id": "mtO4eLhve8MN",
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PvBbCPJie8ct"
   },
   "source": [
    "# LOO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "aborted",
     "timestamp": 1679952551346,
     "user": {
      "displayName": "Patrick Cao",
      "userId": "14491048743324317279"
     },
     "user_tz": 240
    },
    "id": "n_HktM31e-EO",
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# guids = val_data.guids\n",
    "# labels = val_data.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "loo = val_data.leave_one_out(3018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compute predicted probabilities on the test set\n",
    "probs = bert_predict(bert_classifier, test_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNbkVKOEvoT5UeHOpUbpwF+",
   "provenance": [
    {
     "file_id": "12fA4kCMggyt4Gz-B2MSi6tFwB3zzyO_O",
     "timestamp": 1679669448099
    }
   ]
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
