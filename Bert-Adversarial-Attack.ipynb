{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43ae37a3-3828-464e-ae74-2516fd1adad5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-09T02:42:03.757471Z",
     "iopub.status.busy": "2023-05-09T02:42:03.757058Z",
     "iopub.status.idle": "2023-05-09T02:42:03.777051Z",
     "shell.execute_reply": "2023-05-09T02:42:03.776224Z",
     "shell.execute_reply.started": "2023-05-09T02:42:03.757445Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "\n",
    "os.environ[\"WANDB_SILENT\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b61d504-4467-43ea-ac73-f0c702bef160",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-09T02:42:18.017002Z",
     "iopub.status.busy": "2023-05-09T02:42:18.016533Z",
     "iopub.status.idle": "2023-05-09T02:42:18.529738Z",
     "shell.execute_reply": "2023-05-09T02:42:18.528826Z",
     "shell.execute_reply.started": "2023-05-09T02:42:18.016983Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import statistics\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import yaml\n",
    "from src import BertClassifier\n",
    "from src import datasets as data_utils\n",
    "from src import influence, train_utils, utils\n",
    "from src.datasets import create_loo_dataset, create_test_sst2, create_train_sst2\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "import wandb\n",
    "\n",
    "device = utils.get_device()\n",
    "\n",
    "# config = utils.load_config(\n",
    "#     \"model_params/bert_classifier.yaml\", epochs=5, num_training_examples=1000\n",
    "# )\n",
    "\n",
    "og_model, config = BertClassifier.load_model(\n",
    "    \"model_params/bert-epoch30-reg0.001-10000.yaml\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a199912-379d-40f2-8443-4508ebb45785",
   "metadata": {},
   "source": [
    "## Create Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d650124e-16b5-4265-8b4d-b286d81cfee7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-09T02:42:19.476627Z",
     "iopub.status.busy": "2023-05-09T02:42:19.476389Z",
     "iopub.status.idle": "2023-05-09T02:42:22.743112Z",
     "shell.execute_reply": "2023-05-09T02:42:22.742158Z",
     "shell.execute_reply.started": "2023-05-09T02:42:19.476612Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:00<00:00, 14321.44it/s]\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 872/872 [00:00<00:00, 10278.97it/s]\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "USE_BERT_EMBEDDINGS = True\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = create_train_sst2(\n",
    "    num_samples=config[\"num_training_examples\"],\n",
    "    tokenizer_name=config[\"bert_model_name\"],\n",
    "    max_seq_len=config[\"max_sequence_length\"],\n",
    "    device=device,\n",
    "    use_bert_embeddings=USE_BERT_EMBEDDINGS,\n",
    ")\n",
    "\n",
    "test_dataset = create_test_sst2(\n",
    "    tokenizer_name=config[\"bert_model_name\"],\n",
    "    max_seq_len=config[\"max_sequence_length\"],\n",
    "    device=device,\n",
    "    use_bert_embeddings=USE_BERT_EMBEDDINGS,\n",
    ")\n",
    "test_dataloader = DataLoader(test_dataset, shuffle=False, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e37995-84b8-48bd-a7c8-0dba09040369",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c808236-ee63-46fe-aef5-2cfb8bab525f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-09T02:42:26.681477Z",
     "iopub.status.busy": "2023-05-09T02:42:26.680727Z",
     "iopub.status.idle": "2023-05-09T02:42:33.343421Z",
     "shell.execute_reply": "2023-05-09T02:42:33.342688Z",
     "shell.execute_reply.started": "2023-05-09T02:42:26.681460Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.37703973579917965, 83.14220183486239)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# full_model, original_df, test_loss, test_acc = train_utils.train_bert_model(\n",
    "#     train_dataset=train_dataset,\n",
    "#     test_dataset=test_dataset,\n",
    "#     config=config,\n",
    "#     use_bert_embeddings=USE_BERT_EMBEDDINGS,\n",
    "# )\n",
    "# test_loss, test_acc\n",
    "fdf, test_loss, test_acc = train_utils.evaluate_loss(og_model, test_dataloader, use_bert_embeddings=True)\n",
    "test_loss, test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98c260f-134c-45a5-a710-a3ced0b55b99",
   "metadata": {},
   "source": [
    "## Adversarial Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "38c66c2d-7243-4936-bf4d-a19a24718bad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-07T23:21:24.814589Z",
     "iopub.status.busy": "2023-05-07T23:21:24.813894Z",
     "iopub.status.idle": "2023-05-07T23:21:24.849702Z",
     "shell.execute_reply": "2023-05-07T23:21:24.848710Z",
     "shell.execute_reply.started": "2023-05-07T23:21:24.814568Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def perturb_datapoint(dataset, data_guid, perturbation):\n",
    "    \"\"\"This modifies the dataset in place\"\"\"\n",
    "    device = utils.get_device()\n",
    "    guid, inputs, attn_mask, labels = [t[data_guid] for t in train_dataset.tensors]\n",
    "    assert guid.squeeze() == data_guid\n",
    "\n",
    "    inputs_before = inputs.detach().clone()\n",
    "    inputs += perturbation.to(device)\n",
    "    return inputs_before, inputs\n",
    "\n",
    "\n",
    "def perform_attack(\n",
    "    model,\n",
    "    config,\n",
    "    train_dataset,\n",
    "    test_dataset,\n",
    "    target_test_guid,\n",
    "    target_train_guid=None,\n",
    "    alpha=2e-2,\n",
    "):\n",
    "    infl = None\n",
    "    if target_train_guid is None:\n",
    "        print(\"---Computing Influence Function---\")\n",
    "        infl = influence.compute_influence(\n",
    "            model,\n",
    "            target_test_guid,\n",
    "            param_influence=list(model.classifier.parameters()),\n",
    "            train_dataset=train_dataset,\n",
    "            test_dataset=test_dataset,\n",
    "            use_bert_embeddings=True,\n",
    "            lissa_r=1,\n",
    "            lissa_depth=1,\n",
    "            damping=5e-3,\n",
    "            scale=100,\n",
    "        )\n",
    "\n",
    "        # Most negative influence is most helpful\n",
    "        helpful_idxs = np.argsort(infl)[:10]\n",
    "        target_train_guid = helpful_idxs[0]\n",
    "\n",
    "    print(\"---Computing Input Influence Function---\")\n",
    "    input_infl = influence.compute_input_influence(\n",
    "        model,\n",
    "        target_test_guid,\n",
    "        param_influence=list(model.classifier.parameters()),\n",
    "        train_dataset=train_dataset,\n",
    "        test_dataset=test_dataset,\n",
    "        use_bert_embeddings=True,\n",
    "        lissa_r=1,\n",
    "        lissa_depth=1,\n",
    "        damping=5e-3,\n",
    "        scale=100,\n",
    "        training_indices=[target_train_guid],\n",
    "    )\n",
    "\n",
    "    print(f\"---Perturbing training guid {target_train_guid}---\")\n",
    "    perturb = alpha * input_infl[target_train_guid]\n",
    "    perturb_datapoint(train_dataset, target_train_guid, perturb)\n",
    "\n",
    "    print(\"---Retraining on perturbed data---\")\n",
    "    # Retrain model on perturbed dataset\n",
    "    model, df, full_test_loss, full_test_acc = train_utils.train_bert_model(\n",
    "        train_dataset=train_dataset,\n",
    "        test_dataset=test_dataset,\n",
    "        config=config,\n",
    "        use_bert_embeddings=True,\n",
    "    )\n",
    "    df[\"perturbed_guid\"] = target_train_guid\n",
    "    return model, df, infl, input_infl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "83e0d214-c4da-4fd3-9c99-a4c052509a40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-08T00:55:14.899127Z",
     "iopub.status.busy": "2023-05-08T00:55:14.898493Z",
     "iopub.status.idle": "2023-05-08T00:55:14.929174Z",
     "shell.execute_reply": "2023-05-08T00:55:14.928385Z",
     "shell.execute_reply.started": "2023-05-08T00:55:14.899109Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "test_guid                        845\n",
       "logits       [0.5202583, -0.6204333]\n",
       "pred                               0\n",
       "label                              0\n",
       "loss                        0.277327\n",
       "Name: 845, dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdf[fdf.pred == fdf.label].sort_values(\"loss\", ascending=False).iloc[200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "76c62a34-7687-43c3-ba88-66fcc9679de3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-08T00:55:31.633152Z",
     "iopub.status.busy": "2023-05-08T00:55:31.632924Z",
     "iopub.status.idle": "2023-05-08T00:55:31.658658Z",
     "shell.execute_reply": "2023-05-08T00:55:31.657834Z",
     "shell.execute_reply.started": "2023-05-08T00:55:31.633137Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27732712030410767"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top 100 can be attacked\n",
    "\n",
    "TEST_GUID = 845\n",
    "\n",
    "baseline_test_loss = fdf[fdf.test_guid == TEST_GUID].loss.squeeze()\n",
    "baseline_test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e57ad744-fabd-4239-90a0-8eaa72b2561f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-08T00:55:45.525833Z",
     "iopub.status.busy": "2023-05-08T00:55:45.525607Z",
     "iopub.status.idle": "2023-05-08T01:21:31.433299Z",
     "shell.execute_reply": "2023-05-08T01:21:31.432632Z",
     "shell.execute_reply.started": "2023-05-08T00:55:45.525819Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Computing Influence Function---\n",
      "LiSSA reps: 1 and num_iterations: 1000\n",
      "Recursion at depth 0: norm is 7.170006\n",
      "Recursion at depth 100: norm is 108.369644\n",
      "Recursion at depth 200: norm is 163.181732\n",
      "Recursion at depth 300: norm is 192.374741\n",
      "Recursion at depth 400: norm is 208.072952\n",
      "Recursion at depth 500: norm is 218.451111\n",
      "Recursion at depth 600: norm is 223.446838\n",
      "Recursion at depth 700: norm is 226.833298\n",
      "Recursion at depth 800: norm is 229.715286\n",
      "Recursion at depth 900: norm is 230.460648\n",
      "Recursion at depth 999: norm is 232.348038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:06<00:00, 147.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Computing Input Influence Function---\n",
      "LiSSA reps: 1 and num_iterations: 1000\n",
      "Recursion at depth 0: norm is 7.114713\n",
      "Recursion at depth 100: norm is 107.310768\n",
      "Recursion at depth 200: norm is 163.592789\n",
      "Recursion at depth 300: norm is 192.630981\n",
      "Recursion at depth 400: norm is 209.661072\n",
      "Recursion at depth 500: norm is 218.678299\n",
      "Recursion at depth 600: norm is 223.884995\n",
      "Recursion at depth 700: norm is 226.265518\n",
      "Recursion at depth 800: norm is 229.755447\n",
      "Recursion at depth 900: norm is 229.281372\n",
      "Recursion at depth 999: norm is 230.660950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:11<00:00, 89.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Perturbing training guid 146---\n",
      "---Retraining on perturbed data---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial 0.41442395658465236, 80.27522935779817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 27.76batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 30.15batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 29.79batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 29.32batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 29.50batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final 0.4042343917438327, 81.19266055045871\n",
      "---Computing Influence Function---\n",
      "LiSSA reps: 1 and num_iterations: 1000\n",
      "Recursion at depth 0: norm is 3.812735\n",
      "Recursion at depth 100: norm is 56.911823\n",
      "Recursion at depth 200: norm is 85.974640\n",
      "Recursion at depth 300: norm is 101.695328\n",
      "Recursion at depth 400: norm is 110.046654\n",
      "Recursion at depth 500: norm is 115.577110\n",
      "Recursion at depth 600: norm is 118.231163\n",
      "Recursion at depth 700: norm is 120.180870\n",
      "Recursion at depth 800: norm is 121.836266\n",
      "Recursion at depth 900: norm is 122.367760\n",
      "Recursion at depth 999: norm is 123.418045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:06<00:00, 147.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Computing Input Influence Function---\n",
      "LiSSA reps: 1 and num_iterations: 1000\n",
      "Recursion at depth 0: norm is 3.779460\n",
      "Recursion at depth 100: norm is 56.005798\n",
      "Recursion at depth 200: norm is 85.901062\n",
      "Recursion at depth 300: norm is 101.519035\n",
      "Recursion at depth 400: norm is 110.650879\n",
      "Recursion at depth 500: norm is 115.933182\n",
      "Recursion at depth 600: norm is 118.817421\n",
      "Recursion at depth 700: norm is 119.999832\n",
      "Recursion at depth 800: norm is 121.885422\n",
      "Recursion at depth 900: norm is 122.058739\n",
      "Recursion at depth 999: norm is 122.373367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:08<00:00, 114.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Perturbing training guid 710---\n",
      "---Retraining on perturbed data---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial 0.41442395658465236, 80.27522935779817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 29.61batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 29.74batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 30.18batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 29.93batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 30.01batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final 0.4043390411532761, 81.53669724770643\n",
      "---Computing Influence Function---\n",
      "LiSSA reps: 1 and num_iterations: 1000\n",
      "Recursion at depth 0: norm is 4.114989\n",
      "Recursion at depth 100: norm is 61.329872\n",
      "Recursion at depth 200: norm is 92.702011\n",
      "Recursion at depth 300: norm is 109.599182\n",
      "Recursion at depth 400: norm is 118.624924\n",
      "Recursion at depth 500: norm is 124.582329\n",
      "Recursion at depth 600: norm is 127.442528\n",
      "Recursion at depth 700: norm is 129.551636\n",
      "Recursion at depth 800: norm is 131.352310\n",
      "Recursion at depth 900: norm is 131.897690\n",
      "Recursion at depth 999: norm is 133.047333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:06<00:00, 147.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Computing Input Influence Function---\n",
      "LiSSA reps: 1 and num_iterations: 1000\n",
      "Recursion at depth 0: norm is 4.075822\n",
      "Recursion at depth 100: norm is 60.361996\n",
      "Recursion at depth 200: norm is 92.578430\n",
      "Recursion at depth 300: norm is 109.431740\n",
      "Recursion at depth 400: norm is 119.318367\n",
      "Recursion at depth 500: norm is 124.969841\n",
      "Recursion at depth 600: norm is 128.114563\n",
      "Recursion at depth 700: norm is 129.382355\n",
      "Recursion at depth 800: norm is 131.407166\n",
      "Recursion at depth 900: norm is 131.584976\n",
      "Recursion at depth 999: norm is 131.951660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:08<00:00, 116.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Perturbing training guid 761---\n",
      "---Retraining on perturbed data---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial 0.41442395658465236, 80.27522935779817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 28.12batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 30.02batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 29.68batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 29.91batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 30.03batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final 0.40607961663677883, 81.65137614678899\n",
      "---Computing Influence Function---\n",
      "LiSSA reps: 1 and num_iterations: 1000\n",
      "Recursion at depth 0: norm is 4.200695\n",
      "Recursion at depth 100: norm is 62.507938\n",
      "Recursion at depth 200: norm is 94.504013\n",
      "Recursion at depth 300: norm is 111.721375\n",
      "Recursion at depth 400: norm is 120.909462\n",
      "Recursion at depth 500: norm is 126.986595\n",
      "Recursion at depth 600: norm is 129.881638\n",
      "Recursion at depth 700: norm is 132.038437\n",
      "Recursion at depth 800: norm is 133.879395\n",
      "Recursion at depth 900: norm is 134.437546\n",
      "Recursion at depth 999: norm is 135.648254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:06<00:00, 146.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Computing Input Influence Function---\n",
      "LiSSA reps: 1 and num_iterations: 1000\n",
      "Recursion at depth 0: norm is 4.152007\n",
      "Recursion at depth 100: norm is 61.538712\n",
      "Recursion at depth 200: norm is 94.463455\n",
      "Recursion at depth 300: norm is 111.585648\n",
      "Recursion at depth 400: norm is 121.656265\n",
      "Recursion at depth 500: norm is 127.390869\n",
      "Recursion at depth 600: norm is 130.604050\n",
      "Recursion at depth 700: norm is 131.884003\n",
      "Recursion at depth 800: norm is 133.937057\n",
      "Recursion at depth 900: norm is 134.109238\n",
      "Recursion at depth 999: norm is 134.525131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:08<00:00, 118.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Perturbing training guid 333---\n",
      "---Retraining on perturbed data---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial 0.41442395658465236, 80.27522935779817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 29.08batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 30.02batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 30.03batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 29.93batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 29.89batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final 0.40578691094715147, 81.65137614678899\n",
      "---Computing Influence Function---\n",
      "LiSSA reps: 1 and num_iterations: 1000\n",
      "Recursion at depth 0: norm is 4.308875\n",
      "Recursion at depth 100: norm is 64.083450\n",
      "Recursion at depth 200: norm is 96.920120\n",
      "Recursion at depth 300: norm is 114.562836\n",
      "Recursion at depth 400: norm is 124.015320\n",
      "Recursion at depth 500: norm is 130.261520\n",
      "Recursion at depth 600: norm is 133.215820\n",
      "Recursion at depth 700: norm is 135.428635\n",
      "Recursion at depth 800: norm is 137.305130\n",
      "Recursion at depth 900: norm is 137.890488\n",
      "Recursion at depth 999: norm is 139.094238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:06<00:00, 155.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Computing Input Influence Function---\n",
      "LiSSA reps: 1 and num_iterations: 1000\n",
      "Recursion at depth 0: norm is 4.254173\n",
      "Recursion at depth 100: norm is 63.107948\n",
      "Recursion at depth 200: norm is 96.878479\n",
      "Recursion at depth 300: norm is 114.433388\n",
      "Recursion at depth 400: norm is 124.787254\n",
      "Recursion at depth 500: norm is 130.663773\n",
      "Recursion at depth 600: norm is 133.969299\n",
      "Recursion at depth 700: norm is 135.251434\n",
      "Recursion at depth 800: norm is 137.358902\n",
      "Recursion at depth 900: norm is 137.518433\n",
      "Recursion at depth 999: norm is 138.036560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:08<00:00, 115.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Perturbing training guid 537---\n",
      "---Retraining on perturbed data---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial 0.41442395658465236, 80.27522935779817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 29.21batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:01<00:00, 31.80batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:01<00:00, 31.69batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 30.61batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 30.56batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final 0.405704633797207, 81.53669724770643\n",
      "---Computing Influence Function---\n",
      "LiSSA reps: 1 and num_iterations: 1000\n",
      "Recursion at depth 0: norm is 4.557305\n",
      "Recursion at depth 100: norm is 67.802437\n",
      "Recursion at depth 200: norm is 102.646263\n",
      "Recursion at depth 300: norm is 121.372925\n",
      "Recursion at depth 400: norm is 131.524567\n",
      "Recursion at depth 500: norm is 138.124100\n",
      "Recursion at depth 600: norm is 141.310989\n",
      "Recursion at depth 700: norm is 143.652771\n",
      "Recursion at depth 800: norm is 145.509705\n",
      "Recursion at depth 900: norm is 146.265472\n",
      "Recursion at depth 999: norm is 147.546951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:06<00:00, 156.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Computing Input Influence Function---\n",
      "LiSSA reps: 1 and num_iterations: 1000\n",
      "Recursion at depth 0: norm is 4.498980\n",
      "Recursion at depth 100: norm is 66.784882\n",
      "Recursion at depth 200: norm is 102.601891\n",
      "Recursion at depth 300: norm is 121.287964\n",
      "Recursion at depth 400: norm is 132.217911\n",
      "Recursion at depth 500: norm is 138.447220\n",
      "Recursion at depth 600: norm is 141.922211\n",
      "Recursion at depth 700: norm is 143.377274\n",
      "Recursion at depth 800: norm is 145.739594\n",
      "Recursion at depth 900: norm is 145.867691\n",
      "Recursion at depth 999: norm is 146.317139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:08<00:00, 115.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Perturbing training guid 911---\n",
      "---Retraining on perturbed data---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial 0.41442395658465236, 80.27522935779817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 31.17batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:01<00:00, 31.74batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 30.53batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 30.65batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:01<00:00, 31.53batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final 0.4052045426429861, 81.65137614678899\n",
      "---Computing Influence Function---\n",
      "LiSSA reps: 1 and num_iterations: 1000\n",
      "Recursion at depth 0: norm is 4.767062\n",
      "Recursion at depth 100: norm is 71.033165\n",
      "Recursion at depth 200: norm is 107.521828\n",
      "Recursion at depth 300: norm is 127.188332\n",
      "Recursion at depth 400: norm is 137.848892\n",
      "Recursion at depth 500: norm is 144.820190\n",
      "Recursion at depth 600: norm is 148.367935\n",
      "Recursion at depth 700: norm is 150.653336\n",
      "Recursion at depth 800: norm is 152.634995\n",
      "Recursion at depth 900: norm is 153.351837\n",
      "Recursion at depth 999: norm is 154.744064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:06<00:00, 155.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Computing Input Influence Function---\n",
      "LiSSA reps: 1 and num_iterations: 1000\n",
      "Recursion at depth 0: norm is 4.705225\n",
      "Recursion at depth 100: norm is 70.038429\n",
      "Recursion at depth 200: norm is 107.667404\n",
      "Recursion at depth 300: norm is 127.245735\n",
      "Recursion at depth 400: norm is 138.700851\n",
      "Recursion at depth 500: norm is 145.083908\n",
      "Recursion at depth 600: norm is 148.746140\n",
      "Recursion at depth 700: norm is 150.630707\n",
      "Recursion at depth 800: norm is 153.088013\n",
      "Recursion at depth 900: norm is 153.075745\n",
      "Recursion at depth 999: norm is 153.429398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:07<00:00, 125.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Perturbing training guid 679---\n",
      "---Retraining on perturbed data---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial 0.41442395658465236, 80.27522935779817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 30.30batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 31.42batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 30.71batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 30.82batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:01<00:00, 31.87batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final 0.4050941927103065, 81.76605504587155\n",
      "---Computing Influence Function---\n",
      "LiSSA reps: 1 and num_iterations: 1000\n",
      "Recursion at depth 0: norm is 4.850146\n",
      "Recursion at depth 100: norm is 72.404839\n",
      "Recursion at depth 200: norm is 109.514061\n",
      "Recursion at depth 300: norm is 129.563202\n",
      "Recursion at depth 400: norm is 140.525574\n",
      "Recursion at depth 500: norm is 147.537659\n",
      "Recursion at depth 600: norm is 151.138229\n",
      "Recursion at depth 700: norm is 153.619125\n",
      "Recursion at depth 800: norm is 155.559677\n",
      "Recursion at depth 900: norm is 156.385361\n",
      "Recursion at depth 999: norm is 157.820190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:06<00:00, 155.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Computing Input Influence Function---\n",
      "LiSSA reps: 1 and num_iterations: 1000\n",
      "Recursion at depth 0: norm is 4.788602\n",
      "Recursion at depth 100: norm is 71.298431\n",
      "Recursion at depth 200: norm is 109.732124\n",
      "Recursion at depth 300: norm is 129.706207\n",
      "Recursion at depth 400: norm is 141.408386\n",
      "Recursion at depth 500: norm is 147.839096\n",
      "Recursion at depth 600: norm is 151.732971\n",
      "Recursion at depth 700: norm is 153.533951\n",
      "Recursion at depth 800: norm is 156.184708\n",
      "Recursion at depth 900: norm is 156.099716\n",
      "Recursion at depth 999: norm is 156.503937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:08<00:00, 119.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Perturbing training guid 617---\n",
      "---Retraining on perturbed data---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial 0.41442395658465236, 80.27522935779817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 30.49batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 30.64batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 30.65batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:01<00:00, 31.50batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:01<00:00, 31.86batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final 0.4052877769350794, 81.88073394495413\n",
      "---Computing Influence Function---\n",
      "LiSSA reps: 1 and num_iterations: 1000\n",
      "Recursion at depth 0: norm is 5.383257\n",
      "Recursion at depth 100: norm is 80.388725\n",
      "Recursion at depth 200: norm is 121.889137\n",
      "Recursion at depth 300: norm is 144.695862\n",
      "Recursion at depth 400: norm is 156.655380\n",
      "Recursion at depth 500: norm is 164.565475\n",
      "Recursion at depth 600: norm is 168.850739\n",
      "Recursion at depth 700: norm is 171.318008\n",
      "Recursion at depth 800: norm is 173.514130\n",
      "Recursion at depth 900: norm is 174.468628\n",
      "Recursion at depth 999: norm is 175.921509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:06<00:00, 154.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Computing Input Influence Function---\n",
      "LiSSA reps: 1 and num_iterations: 1000\n",
      "Recursion at depth 0: norm is 5.315162\n",
      "Recursion at depth 100: norm is 79.369843\n",
      "Recursion at depth 200: norm is 122.113235\n",
      "Recursion at depth 300: norm is 144.626007\n",
      "Recursion at depth 400: norm is 157.396133\n",
      "Recursion at depth 500: norm is 164.886673\n",
      "Recursion at depth 600: norm is 169.255020\n",
      "Recursion at depth 700: norm is 171.504471\n",
      "Recursion at depth 800: norm is 174.144165\n",
      "Recursion at depth 900: norm is 173.828583\n",
      "Recursion at depth 999: norm is 174.379166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:07<00:00, 125.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Perturbing training guid 293---\n",
      "---Retraining on perturbed data---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial 0.41442395658465236, 80.27522935779817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 29.25batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 30.60batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 30.63batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:01<00:00, 31.82batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:01<00:00, 31.73batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final 0.4046800692463592, 81.88073394495413\n",
      "---Computing Influence Function---\n",
      "LiSSA reps: 1 and num_iterations: 1000\n",
      "Recursion at depth 0: norm is 5.509279\n",
      "Recursion at depth 100: norm is 82.287788\n",
      "Recursion at depth 200: norm is 124.837006\n",
      "Recursion at depth 300: norm is 148.151215\n",
      "Recursion at depth 400: norm is 160.343307\n",
      "Recursion at depth 500: norm is 168.454758\n",
      "Recursion at depth 600: norm is 172.895065\n",
      "Recursion at depth 700: norm is 175.449173\n",
      "Recursion at depth 800: norm is 177.640167\n",
      "Recursion at depth 900: norm is 178.640747\n",
      "Recursion at depth 999: norm is 180.077225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:06<00:00, 153.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Computing Input Influence Function---\n",
      "LiSSA reps: 1 and num_iterations: 1000\n",
      "Recursion at depth 0: norm is 5.445246\n",
      "Recursion at depth 100: norm is 81.289658\n",
      "Recursion at depth 200: norm is 125.013710\n",
      "Recursion at depth 300: norm is 148.064499\n",
      "Recursion at depth 400: norm is 161.111496\n",
      "Recursion at depth 500: norm is 168.800980\n",
      "Recursion at depth 600: norm is 173.255356\n",
      "Recursion at depth 700: norm is 175.552261\n",
      "Recursion at depth 800: norm is 178.308258\n",
      "Recursion at depth 900: norm is 177.936935\n",
      "Recursion at depth 999: norm is 178.517288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:08<00:00, 119.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Perturbing training guid 843---\n",
      "---Retraining on perturbed data---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial 0.41442395658465236, 80.27522935779817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 30.28batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 30.57batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 31.20batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:01<00:00, 31.81batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:01<00:00, 31.65batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final 0.40599794562017494, 81.76605504587155\n",
      "---Computing Influence Function---\n",
      "LiSSA reps: 1 and num_iterations: 1000\n",
      "Recursion at depth 0: norm is 5.723131\n",
      "Recursion at depth 100: norm is 85.718185\n",
      "Recursion at depth 200: norm is 129.875565\n",
      "Recursion at depth 300: norm is 154.039871\n",
      "Recursion at depth 400: norm is 166.901352\n",
      "Recursion at depth 500: norm is 175.192505\n",
      "Recursion at depth 600: norm is 179.940109\n",
      "Recursion at depth 700: norm is 182.449600\n",
      "Recursion at depth 800: norm is 184.754150\n",
      "Recursion at depth 900: norm is 185.881989\n",
      "Recursion at depth 999: norm is 187.404724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:06<00:00, 146.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Computing Input Influence Function---\n",
      "LiSSA reps: 1 and num_iterations: 1000\n",
      "Recursion at depth 0: norm is 5.653793\n",
      "Recursion at depth 100: norm is 84.523460\n",
      "Recursion at depth 200: norm is 129.943069\n",
      "Recursion at depth 300: norm is 153.993195\n",
      "Recursion at depth 400: norm is 167.522720\n",
      "Recursion at depth 500: norm is 175.483688\n",
      "Recursion at depth 600: norm is 180.414780\n",
      "Recursion at depth 700: norm is 182.603516\n",
      "Recursion at depth 800: norm is 185.570145\n",
      "Recursion at depth 900: norm is 185.186203\n",
      "Recursion at depth 999: norm is 185.734680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:07<00:00, 126.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Perturbing training guid 123---\n",
      "---Retraining on perturbed data---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial 0.41442395658465236, 80.27522935779817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 28.55batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 31.14batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:01<00:00, 31.59batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 31.39batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:01<00:00, 31.55batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final 0.4061710361592129, 81.88073394495413\n",
      "---Computing Influence Function---\n",
      "LiSSA reps: 1 and num_iterations: 1000\n",
      "Recursion at depth 0: norm is 5.797697\n",
      "Recursion at depth 100: norm is 86.834892\n",
      "Recursion at depth 200: norm is 131.618866\n",
      "Recursion at depth 300: norm is 156.152405\n",
      "Recursion at depth 400: norm is 169.137146\n",
      "Recursion at depth 500: norm is 177.535751\n",
      "Recursion at depth 600: norm is 182.312698\n",
      "Recursion at depth 700: norm is 184.850372\n",
      "Recursion at depth 800: norm is 187.211441\n",
      "Recursion at depth 900: norm is 188.378082\n",
      "Recursion at depth 999: norm is 189.868942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:06<00:00, 162.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Computing Input Influence Function---\n",
      "LiSSA reps: 1 and num_iterations: 1000\n",
      "Recursion at depth 0: norm is 5.729347\n",
      "Recursion at depth 100: norm is 85.629501\n",
      "Recursion at depth 200: norm is 131.678726\n",
      "Recursion at depth 300: norm is 156.011093\n",
      "Recursion at depth 400: norm is 169.728363\n",
      "Recursion at depth 500: norm is 177.809952\n",
      "Recursion at depth 600: norm is 182.788940\n",
      "Recursion at depth 700: norm is 185.082199\n",
      "Recursion at depth 800: norm is 188.024719\n",
      "Recursion at depth 900: norm is 187.623642\n",
      "Recursion at depth 999: norm is 188.206329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:08<00:00, 124.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Perturbing training guid 198---\n",
      "---Retraining on perturbed data---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial 0.41442395658465236, 80.27522935779817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 28.76batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 30.36batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 30.76batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:01<00:00, 31.98batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:01<00:00, 31.78batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final 0.40602399776891884, 81.88073394495413\n",
      "---Computing Influence Function---\n",
      "LiSSA reps: 1 and num_iterations: 1000\n",
      "Recursion at depth 0: norm is 5.947155\n",
      "Recursion at depth 100: norm is 89.129723\n",
      "Recursion at depth 200: norm is 135.055359\n",
      "Recursion at depth 300: norm is 160.272842\n",
      "Recursion at depth 400: norm is 173.608734\n",
      "Recursion at depth 500: norm is 182.460327\n",
      "Recursion at depth 600: norm is 187.183685\n",
      "Recursion at depth 700: norm is 189.839966\n",
      "Recursion at depth 800: norm is 192.263565\n",
      "Recursion at depth 900: norm is 193.490829\n",
      "Recursion at depth 999: norm is 194.938950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:06<00:00, 144.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Computing Input Influence Function---\n",
      "LiSSA reps: 1 and num_iterations: 1000\n",
      "Recursion at depth 0: norm is 5.880088\n",
      "Recursion at depth 100: norm is 87.954781\n",
      "Recursion at depth 200: norm is 135.231644\n",
      "Recursion at depth 300: norm is 160.180130\n",
      "Recursion at depth 400: norm is 174.332626\n",
      "Recursion at depth 500: norm is 182.563950\n",
      "Recursion at depth 600: norm is 187.739471\n",
      "Recursion at depth 700: norm is 190.031189\n",
      "Recursion at depth 800: norm is 193.079681\n",
      "Recursion at depth 900: norm is 192.645935\n",
      "Recursion at depth 999: norm is 193.475754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:07<00:00, 127.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Perturbing training guid 475---\n",
      "---Retraining on perturbed data---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial 0.41442395658465236, 80.27522935779817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 30.29batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:01<00:00, 31.61batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:01<00:00, 31.71batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:01<00:00, 31.76batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 30.92batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final 0.40711668229050285, 81.9954128440367\n",
      "---Computing Influence Function---\n",
      "LiSSA reps: 1 and num_iterations: 1000\n",
      "Recursion at depth 0: norm is 6.085615\n",
      "Recursion at depth 100: norm is 91.222031\n",
      "Recursion at depth 200: norm is 138.399170\n",
      "Recursion at depth 300: norm is 164.389511\n",
      "Recursion at depth 400: norm is 178.163376\n",
      "Recursion at depth 500: norm is 187.030563\n",
      "Recursion at depth 600: norm is 191.916031\n",
      "Recursion at depth 700: norm is 194.520950\n",
      "Recursion at depth 800: norm is 197.171127\n",
      "Recursion at depth 900: norm is 198.346329\n",
      "Recursion at depth 999: norm is 199.906982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:06<00:00, 153.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Computing Input Influence Function---\n",
      "LiSSA reps: 1 and num_iterations: 1000\n",
      "Recursion at depth 0: norm is 6.019671\n",
      "Recursion at depth 100: norm is 90.125275\n",
      "Recursion at depth 200: norm is 138.642578\n",
      "Recursion at depth 300: norm is 164.207565\n",
      "Recursion at depth 400: norm is 178.624863\n",
      "Recursion at depth 500: norm is 187.050903\n",
      "Recursion at depth 600: norm is 192.388123\n",
      "Recursion at depth 700: norm is 194.764008\n",
      "Recursion at depth 800: norm is 197.904938\n",
      "Recursion at depth 900: norm is 197.434250\n",
      "Recursion at depth 999: norm is 198.388199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:07<00:00, 127.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Perturbing training guid 468---\n",
      "---Retraining on perturbed data---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial 0.41442395658465236, 80.27522935779817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 28.69batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 31.38batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:01<00:00, 31.74batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:01<00:00, 31.63batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 31.07batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final 0.4074564576307773, 82.11009174311927\n",
      "---Computing Influence Function---\n",
      "LiSSA reps: 1 and num_iterations: 1000\n",
      "Recursion at depth 0: norm is 6.163350\n",
      "Recursion at depth 100: norm is 92.453560\n",
      "Recursion at depth 200: norm is 140.265411\n",
      "Recursion at depth 300: norm is 166.610580\n",
      "Recursion at depth 400: norm is 180.568741\n",
      "Recursion at depth 500: norm is 189.556839\n",
      "Recursion at depth 600: norm is 194.519928\n",
      "Recursion at depth 700: norm is 197.134140\n",
      "Recursion at depth 800: norm is 199.827347\n",
      "Recursion at depth 900: norm is 201.067719\n",
      "Recursion at depth 999: norm is 202.600281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:06<00:00, 149.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Computing Input Influence Function---\n",
      "LiSSA reps: 1 and num_iterations: 1000\n",
      "Recursion at depth 0: norm is 6.098562\n",
      "Recursion at depth 100: norm is 91.304008\n",
      "Recursion at depth 200: norm is 140.497284\n",
      "Recursion at depth 300: norm is 166.437561\n",
      "Recursion at depth 400: norm is 181.042679\n",
      "Recursion at depth 500: norm is 189.545715\n",
      "Recursion at depth 600: norm is 194.938980\n",
      "Recursion at depth 700: norm is 197.387009\n",
      "Recursion at depth 800: norm is 200.562332\n",
      "Recursion at depth 900: norm is 200.110458\n",
      "Recursion at depth 999: norm is 201.062729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:07<00:00, 127.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Perturbing training guid 237---\n",
      "---Retraining on perturbed data---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial 0.41442395658465236, 80.27522935779817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 30.45batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:01<00:00, 31.67batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 30.78batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 29.80batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 30.91batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final 0.4088614702345444, 81.9954128440367\n"
     ]
    }
   ],
   "source": [
    "# target_train_guid = 262\n",
    "\n",
    "hist = {\n",
    "    \"loss_df\": [],\n",
    "    \"influence\": [],\n",
    "    \"input_influence\": [],\n",
    "}\n",
    "model = og_model\n",
    "for i in range(15):\n",
    "    model, loss_df, infl, input_infl = perform_attack(\n",
    "        model=model,\n",
    "        config=config,\n",
    "        train_dataset=train_dataset,\n",
    "        test_dataset=test_dataset,\n",
    "        target_test_guid=TEST_GUID,\n",
    "        alpha=5e-1,\n",
    "        # target_train_guid=target_train_guid,\n",
    "    )\n",
    "    loss_df[\"iter\"] = i\n",
    "\n",
    "    hist[\"loss_df\"].append(loss_df)\n",
    "    hist[\"influence\"].append(infl)\n",
    "    hist[\"input_influence\"].append(input_infl)\n",
    "    \n",
    "    test_df = loss_df[loss_df.test_guid == TEST_GUID]\n",
    "    if test_df.pred.squeeze() != test_df.label.squeeze():\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "93ada11b-7f2f-4d9a-9a73-5851df2687ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-08T00:20:07.280911Z",
     "iopub.status.busy": "2023-05-08T00:20:07.280733Z",
     "iopub.status.idle": "2023-05-08T00:20:07.313422Z",
     "shell.execute_reply": "2023-05-08T00:20:07.312719Z",
     "shell.execute_reply.started": "2023-05-08T00:20:07.280895Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_guid</th>\n",
       "      <th>logits</th>\n",
       "      <th>pred</th>\n",
       "      <th>label</th>\n",
       "      <th>loss</th>\n",
       "      <th>perturbed_guid</th>\n",
       "      <th>iter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>835</td>\n",
       "      <td>[-0.2794927, 0.1258931]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.510857</td>\n",
       "      <td>283</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>835</td>\n",
       "      <td>[-0.23010865, 0.07639963]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.551591</td>\n",
       "      <td>674</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>835</td>\n",
       "      <td>[-0.21975267, 0.06545623]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.560677</td>\n",
       "      <td>636</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>835</td>\n",
       "      <td>[-0.22391771, 0.06937532]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.557215</td>\n",
       "      <td>861</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>835</td>\n",
       "      <td>[-0.19686149, 0.042281836]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.580707</td>\n",
       "      <td>91</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>835</td>\n",
       "      <td>[-0.18992358, 0.03470982]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.587125</td>\n",
       "      <td>486</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>835</td>\n",
       "      <td>[-0.15941639, 0.004119546]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.614719</td>\n",
       "      <td>281</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>835</td>\n",
       "      <td>[-0.1041629, -0.051154472]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666994</td>\n",
       "      <td>94</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>835</td>\n",
       "      <td>[-0.0863075, -0.06904605]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.684554</td>\n",
       "      <td>693</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>835</td>\n",
       "      <td>[-0.028598854, -0.12658453]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.743340</td>\n",
       "      <td>746</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     test_guid                       logits  pred  label      loss  \\\n",
       "835        835      [-0.2794927, 0.1258931]     1      1  0.510857   \n",
       "835        835    [-0.23010865, 0.07639963]     1      1  0.551591   \n",
       "835        835    [-0.21975267, 0.06545623]     1      1  0.560677   \n",
       "835        835    [-0.22391771, 0.06937532]     1      1  0.557215   \n",
       "835        835   [-0.19686149, 0.042281836]     1      1  0.580707   \n",
       "835        835    [-0.18992358, 0.03470982]     1      1  0.587125   \n",
       "835        835   [-0.15941639, 0.004119546]     1      1  0.614719   \n",
       "835        835   [-0.1041629, -0.051154472]     1      1  0.666994   \n",
       "835        835    [-0.0863075, -0.06904605]     1      1  0.684554   \n",
       "835        835  [-0.028598854, -0.12658453]     0      1  0.743340   \n",
       "\n",
       "     perturbed_guid  iter  \n",
       "835             283     0  \n",
       "835             674     1  \n",
       "835             636     2  \n",
       "835             861     3  \n",
       "835              91     4  \n",
       "835             486     5  \n",
       "835             281     6  \n",
       "835              94     7  \n",
       "835             693     8  \n",
       "835             746     9  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat(hist[\"loss_df\"])\n",
    "df[df.test_guid == TEST_GUID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "91b0cab9-7c9e-4929-94c1-7eddb16b8ea2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-07T22:27:56.448085Z",
     "iopub.status.busy": "2023-05-07T22:27:56.447398Z",
     "iopub.status.idle": "2023-05-07T22:27:56.480376Z",
     "shell.execute_reply": "2023-05-07T22:27:56.479540Z",
     "shell.execute_reply.started": "2023-05-07T22:27:56.448064Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_guid</th>\n",
       "      <th>logits</th>\n",
       "      <th>pred</th>\n",
       "      <th>label</th>\n",
       "      <th>loss</th>\n",
       "      <th>perturbed_guid</th>\n",
       "      <th>iter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>175</td>\n",
       "      <td>[0.674652, -0.7781812]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.663018</td>\n",
       "      <td>455</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>175</td>\n",
       "      <td>[0.72075385, -0.82425386]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.738360</td>\n",
       "      <td>861</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>175</td>\n",
       "      <td>[0.745123, -0.84857845]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.778663</td>\n",
       "      <td>693</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>175</td>\n",
       "      <td>[0.7943765, -0.8980169]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.861358</td>\n",
       "      <td>486</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>175</td>\n",
       "      <td>[0.8068535, -0.90997225]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.882031</td>\n",
       "      <td>94</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>175</td>\n",
       "      <td>[0.81793123, -0.9210918]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.900880</td>\n",
       "      <td>91</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>175</td>\n",
       "      <td>[0.82862556, -0.93167734]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.919008</td>\n",
       "      <td>636</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>175</td>\n",
       "      <td>[0.8473495, -0.95056677]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.951190</td>\n",
       "      <td>686</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>175</td>\n",
       "      <td>[0.8550431, -0.9582516]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.964397</td>\n",
       "      <td>910</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>175</td>\n",
       "      <td>[0.86175734, -0.9652028]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.976157</td>\n",
       "      <td>837</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     test_guid                     logits  pred  label      loss  \\\n",
       "175        175     [0.674652, -0.7781812]     0      1  1.663018   \n",
       "175        175  [0.72075385, -0.82425386]     0      1  1.738360   \n",
       "175        175    [0.745123, -0.84857845]     0      1  1.778663   \n",
       "175        175    [0.7943765, -0.8980169]     0      1  1.861358   \n",
       "175        175   [0.8068535, -0.90997225]     0      1  1.882031   \n",
       "175        175   [0.81793123, -0.9210918]     0      1  1.900880   \n",
       "175        175  [0.82862556, -0.93167734]     0      1  1.919008   \n",
       "175        175   [0.8473495, -0.95056677]     0      1  1.951190   \n",
       "175        175    [0.8550431, -0.9582516]     0      1  1.964397   \n",
       "175        175   [0.86175734, -0.9652028]     0      1  1.976157   \n",
       "\n",
       "     perturbed_guid  iter  \n",
       "175             455     0  \n",
       "175             861     1  \n",
       "175             693     2  \n",
       "175             486     3  \n",
       "175              94     4  \n",
       "175              91     5  \n",
       "175             636     6  \n",
       "175             686     7  \n",
       "175             910     8  \n",
       "175             837     9  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat(hist[\"loss_df\"])\n",
    "df[df.test_guid == TEST_GUID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fc258488-99ec-4b2a-ba02-bea22c35d2e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-07T22:31:48.269888Z",
     "iopub.status.busy": "2023-05-07T22:31:48.269639Z",
     "iopub.status.idle": "2023-05-07T22:31:48.295917Z",
     "shell.execute_reply": "2023-05-07T22:31:48.295259Z",
     "shell.execute_reply.started": "2023-05-07T22:31:48.269872Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d672f02-0678-4cae-acbb-031add5c6742",
   "metadata": {},
   "outputs": [],
   "source": [
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee79f5b-b737-47a6-adc9-959f402e4a3e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd99cc36-5593-42ad-85c4-aa450128582d",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T00:48:23.253953Z",
     "iopub.status.idle": "2023-05-07T00:48:23.254176Z",
     "shell.execute_reply": "2023-05-07T00:48:23.254082Z",
     "shell.execute_reply.started": "2023-05-07T00:48:23.254072Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model2, loss_df2 = perform_attack(model, config, train_dataset, test_dataset, TEST_GUID)\n",
    "loss_df2[loss_df2.test_guid == TEST_GUID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adae75ff-6482-4f28-b01f-3ceb188e4836",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T00:48:23.255250Z",
     "iopub.status.idle": "2023-05-07T00:48:23.255597Z",
     "shell.execute_reply": "2023-05-07T00:48:23.255454Z",
     "shell.execute_reply.started": "2023-05-07T00:48:23.255439Z"
    }
   },
   "outputs": [],
   "source": [
    "model3, loss_df3 = perform_attack(\n",
    "    model2, config, train_dataset, test_dataset, TEST_GUID\n",
    ")\n",
    "loss_df3[loss_df3.test_guid == TEST_GUID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1761d131-4840-44c0-be1d-6939cd4355f1",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T00:48:23.257194Z",
     "iopub.status.idle": "2023-05-07T00:48:23.257451Z",
     "shell.execute_reply": "2023-05-07T00:48:23.257351Z",
     "shell.execute_reply.started": "2023-05-07T00:48:23.257340Z"
    }
   },
   "outputs": [],
   "source": [
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cded59fc-a91e-4172-ac82-03721c8a96b1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Compute Influence Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc021eb5-80e7-4766-aa3e-5c3e62670838",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T00:48:23.258247Z",
     "iopub.status.idle": "2023-05-07T00:48:23.258464Z",
     "shell.execute_reply": "2023-05-07T00:48:23.258372Z",
     "shell.execute_reply.started": "2023-05-07T00:48:23.258362Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TEST_GUID = 716\n",
    "\n",
    "infl = influence.compute_influence(\n",
    "    full_model,\n",
    "    TEST_GUID,\n",
    "    param_influence=list(full_model.classifier.parameters()),\n",
    "    train_dataset=train_dataset,\n",
    "    test_dataset=test_dataset,\n",
    "    use_bert_embeddings=USE_BERT_EMBEDDINGS,\n",
    "    lissa_r=2,\n",
    "    lissa_depth=1,\n",
    "    damping=5e-3,\n",
    "    scale=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79a9e73-027e-44e0-8f7e-3db986781519",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T00:48:23.259734Z",
     "iopub.status.idle": "2023-05-07T00:48:23.260029Z",
     "shell.execute_reply": "2023-05-07T00:48:23.259919Z",
     "shell.execute_reply.started": "2023-05-07T00:48:23.259883Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Most negative influence is most helpful\n",
    "helpful_idxs = np.argsort(infl)[:10]\n",
    "helpful_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616eba86-7603-47b1-9d1e-310ba5f91297",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T00:48:23.261132Z",
     "iopub.status.idle": "2023-05-07T00:48:23.261364Z",
     "shell.execute_reply": "2023-05-07T00:48:23.261270Z",
     "shell.execute_reply.started": "2023-05-07T00:48:23.261260Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.take(infl, helpful_idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d02bf0-e609-4222-997a-4891051e762b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Compute Input Influence Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a305507-f74f-434c-8c00-be1d73eef30c",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T00:48:23.262135Z",
     "iopub.status.idle": "2023-05-07T00:48:23.262346Z",
     "shell.execute_reply": "2023-05-07T00:48:23.262255Z",
     "shell.execute_reply.started": "2023-05-07T00:48:23.262246Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_infl = influence.compute_input_influence(\n",
    "    full_model,\n",
    "    TEST_GUID,\n",
    "    param_influence=list(full_model.classifier.parameters()),\n",
    "    train_dataset=train_dataset,\n",
    "    test_dataset=test_dataset,\n",
    "    use_bert_embeddings=USE_BERT_EMBEDDINGS,\n",
    "    lissa_r=2,\n",
    "    lissa_depth=1,\n",
    "    damping=5e-3,\n",
    "    scale=100,\n",
    "    training_indices=helpful_idxs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453d8bbb-17b9-4a0b-a9ef-46693bdf3685",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T00:48:23.262969Z",
     "iopub.status.idle": "2023-05-07T00:48:23.263164Z",
     "shell.execute_reply": "2023-05-07T00:48:23.263077Z",
     "shell.execute_reply.started": "2023-05-07T00:48:23.263068Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_idx = helpful_idxs[0]\n",
    "best_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6333341-1e0f-4b2b-9ea6-4eb6a0fe2887",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Perturb the Best Idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91765c3-06a2-4ad0-8ea2-0f661ce17174",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T00:48:23.263717Z",
     "iopub.status.idle": "2023-05-07T00:48:23.264024Z",
     "shell.execute_reply": "2023-05-07T00:48:23.263825Z",
     "shell.execute_reply.started": "2023-05-07T00:48:23.263816Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_guid(dataset, data_guid):\n",
    "    pass\n",
    "\n",
    "\n",
    "def perturb_datapoint(dataset, data_guid, perturbation):\n",
    "    \"\"\"This modifies the dataset in place\"\"\"\n",
    "    device = utils.get_device()\n",
    "    guid, inputs, attn_mask, labels = [t[data_guid] for t in train_dataset.tensors]\n",
    "    assert guid.squeeze() == data_guid\n",
    "\n",
    "    inputs_before = inputs.detach().clone()\n",
    "    inputs += perturbation.to(device)\n",
    "    return inputs_before, inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a679d057-fba5-43b5-80e0-87a1cc0182dd",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T00:48:23.265061Z",
     "iopub.status.idle": "2023-05-07T00:48:23.265259Z",
     "shell.execute_reply": "2023-05-07T00:48:23.265172Z",
     "shell.execute_reply.started": "2023-05-07T00:48:23.265162Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "alpha = 1e-2\n",
    "\n",
    "perturb = alpha * input_infl[best_idx]\n",
    "before, after = perturb_datapoint(train_dataset, best_idx, perturb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edd2dac-5be5-4722-92d9-53477d7f76ac",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Retrain model with new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355e9119-2b25-402d-ae45-19c9c363a476",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T00:48:23.266413Z",
     "iopub.status.idle": "2023-05-07T00:48:23.266621Z",
     "shell.execute_reply": "2023-05-07T00:48:23.266521Z",
     "shell.execute_reply.started": "2023-05-07T00:48:23.266511Z"
    }
   },
   "outputs": [],
   "source": [
    "model, df, full_test_loss, full_test_acc = train_utils.train_bert_model(\n",
    "    train_dataset=train_dataset,\n",
    "    test_dataset=test_dataset,\n",
    "    config=config,\n",
    "    use_bert_embeddings=USE_BERT_EMBEDDINGS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b824ce68-ecd5-4ea3-9210-2feb4415a281",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T00:48:23.267253Z",
     "iopub.status.idle": "2023-05-07T00:48:23.267448Z",
     "shell.execute_reply": "2023-05-07T00:48:23.267362Z",
     "shell.execute_reply.started": "2023-05-07T00:48:23.267353Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_loss = df[df.test_guid == TEST_GUID].loss.squeeze()\n",
    "test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6aa9224-8ac0-4eff-8d81-ce14637d31d1",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T00:48:23.268254Z",
     "iopub.status.idle": "2023-05-07T00:48:23.268447Z",
     "shell.execute_reply": "2023-05-07T00:48:23.268361Z",
     "shell.execute_reply.started": "2023-05-07T00:48:23.268352Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[df.test_guid == TEST_GUID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04445757-1ab6-45a4-883b-1d5c4e60e032",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T00:48:23.269452Z",
     "iopub.status.idle": "2023-05-07T00:48:23.269670Z",
     "shell.execute_reply": "2023-05-07T00:48:23.269582Z",
     "shell.execute_reply.started": "2023-05-07T00:48:23.269572Z"
    }
   },
   "outputs": [],
   "source": [
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63422e9-1f40-44ce-9902-455dfdcf7bff",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T00:48:23.270488Z",
     "iopub.status.idle": "2023-05-07T00:48:23.270697Z",
     "shell.execute_reply": "2023-05-07T00:48:23.270610Z",
     "shell.execute_reply.started": "2023-05-07T00:48:23.270600Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd2805d-c783-4d22-96f0-ff44276855dd",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T00:48:23.271156Z",
     "iopub.status.idle": "2023-05-07T00:48:23.271356Z",
     "shell.execute_reply": "2023-05-07T00:48:23.271269Z",
     "shell.execute_reply.started": "2023-05-07T00:48:23.271259Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ba1c52-4cee-4e2f-b54f-ee96d3684f35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80a68aa-216f-4954-8785-23f41e3cc9c1",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T00:48:23.271936Z",
     "iopub.status.idle": "2023-05-07T00:48:23.272132Z",
     "shell.execute_reply": "2023-05-07T00:48:23.272044Z",
     "shell.execute_reply.started": "2023-05-07T00:48:23.272035Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "guid, inputs, attn_mask, labels = [t[data_guid] for t in train_dataset.tensors]\n",
    "\n",
    "inputs[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a69a0e5-15b5-458e-8828-d5ef82c068b2",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T00:48:23.273006Z",
     "iopub.status.idle": "2023-05-07T00:48:23.273220Z",
     "shell.execute_reply": "2023-05-07T00:48:23.273128Z",
     "shell.execute_reply.started": "2023-05-07T00:48:23.273119Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "guid, inputs, attn_mask, labels = [t[262] for t in train_dataset.tensors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08f607a-b99a-4d15-ae35-b6984969bba0",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T00:48:23.274298Z",
     "iopub.status.idle": "2023-05-07T00:48:23.274506Z",
     "shell.execute_reply": "2023-05-07T00:48:23.274417Z",
     "shell.execute_reply.started": "2023-05-07T00:48:23.274408Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f81f2f-76c4-4786-b760-bb978bd550ae",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T00:48:23.275627Z",
     "iopub.status.idle": "2023-05-07T00:48:23.275831Z",
     "shell.execute_reply": "2023-05-07T00:48:23.275743Z",
     "shell.execute_reply.started": "2023-05-07T00:48:23.275734Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# inputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743304c1-9f64-43ea-b2e3-9371fc812e75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15407823-c8f9-4152-917f-90f2afbed45f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5534f87-9724-4f8b-9bdb-7a1eb7e74861",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T00:48:23.276782Z",
     "iopub.status.idle": "2023-05-07T00:48:23.276978Z",
     "shell.execute_reply": "2023-05-07T00:48:23.276891Z",
     "shell.execute_reply.started": "2023-05-07T00:48:23.276882Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370d28b1-c85a-4f74-957c-d145fc788b47",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T00:48:23.277748Z",
     "iopub.status.idle": "2023-05-07T00:48:23.277943Z",
     "shell.execute_reply": "2023-05-07T00:48:23.277857Z",
     "shell.execute_reply.started": "2023-05-07T00:48:23.277848Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs += perturb.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4840791b-35a4-494f-ad0a-3e81b51b72b9",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T00:48:23.278801Z",
     "iopub.status.idle": "2023-05-07T00:48:23.278999Z",
     "shell.execute_reply": "2023-05-07T00:48:23.278911Z",
     "shell.execute_reply.started": "2023-05-07T00:48:23.278902Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e562a8f-b82e-478a-9709-b3e390de60f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6307729d-8f62-474c-a17f-554f0bd04db2",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T00:48:23.279977Z",
     "iopub.status.idle": "2023-05-07T00:48:23.280178Z",
     "shell.execute_reply": "2023-05-07T00:48:23.280090Z",
     "shell.execute_reply.started": "2023-05-07T00:48:23.280080Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_infl[262]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b985181-9737-477a-b767-7768cee06604",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T00:48:23.280889Z",
     "iopub.status.idle": "2023-05-07T00:48:23.281083Z",
     "shell.execute_reply": "2023-05-07T00:48:23.280997Z",
     "shell.execute_reply.started": "2023-05-07T00:48:23.280987Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"input_infl.pkl\", \"wb\") as fh:\n",
    "    pickle.dump(input_infl, fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e83797-584e-4cb0-834b-9d67ab90092d",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T00:48:23.281912Z",
     "iopub.status.idle": "2023-05-07T00:48:23.282116Z",
     "shell.execute_reply": "2023-05-07T00:48:23.282027Z",
     "shell.execute_reply.started": "2023-05-07T00:48:23.282018Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "262 in helpful_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7315cae-79d4-44e6-a46f-5747b6432232",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T00:48:23.283197Z",
     "iopub.status.idle": "2023-05-07T00:48:23.283393Z",
     "shell.execute_reply": "2023-05-07T00:48:23.283306Z",
     "shell.execute_reply.started": "2023-05-07T00:48:23.283296Z"
    }
   },
   "outputs": [],
   "source": [
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83554cab-505a-4625-af7c-7f8bd67a112d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b535adce-67f9-4691-b378-549184a65661",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T00:48:23.284179Z",
     "iopub.status.idle": "2023-05-07T00:48:23.284373Z",
     "shell.execute_reply": "2023-05-07T00:48:23.284286Z",
     "shell.execute_reply.started": "2023-05-07T00:48:23.284277Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors, Word2Vec\n",
    "\n",
    "w2v = KeyedVectors.load(\"word2vec/glove-twitter-100.kv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91972328-d099-4c87-a2aa-affe2b49bcc2",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T00:48:23.286191Z",
     "iopub.status.idle": "2023-05-07T00:48:23.286410Z",
     "shell.execute_reply": "2023-05-07T00:48:23.286317Z",
     "shell.execute_reply.started": "2023-05-07T00:48:23.286306Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "w2v[\"spielberg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a2e76f-7b63-4b43-8c56-88a3dfe08efa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e3d843-28ab-4021-afc7-46e3f6793576",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32778a7-5a9e-4dda-9716-4d1cfcbb97f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
