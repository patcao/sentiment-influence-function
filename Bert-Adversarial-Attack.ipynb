{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43ae37a3-3828-464e-ae74-2516fd1adad5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-07T00:08:01.852976Z",
     "iopub.status.busy": "2023-05-07T00:08:01.852772Z",
     "iopub.status.idle": "2023-05-07T00:08:01.872140Z",
     "shell.execute_reply": "2023-05-07T00:08:01.871285Z",
     "shell.execute_reply.started": "2023-05-07T00:08:01.852960Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "\n",
    "os.environ[\"WANDB_SILENT\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b61d504-4467-43ea-ac73-f0c702bef160",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-07T00:08:01.873934Z",
     "iopub.status.busy": "2023-05-07T00:08:01.873516Z",
     "iopub.status.idle": "2023-05-07T00:08:03.672122Z",
     "shell.execute_reply": "2023-05-07T00:08:03.671385Z",
     "shell.execute_reply.started": "2023-05-07T00:08:01.873918Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import statistics\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import yaml\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "import wandb\n",
    "from src import BertClassifier\n",
    "from src import datasets as data_utils\n",
    "from src import influence, train_utils, utils\n",
    "from src.datasets import create_loo_dataset, create_test_sst2, create_train_sst2\n",
    "\n",
    "device = utils.get_device()\n",
    "\n",
    "config = utils.load_config(\n",
    "    \"model_params/bert_classifier.yaml\", epochs=5, num_training_examples=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a199912-379d-40f2-8443-4508ebb45785",
   "metadata": {},
   "source": [
    "## Create Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d650124e-16b5-4265-8b4d-b286d81cfee7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-07T00:08:03.673013Z",
     "iopub.status.busy": "2023-05-07T00:08:03.672739Z",
     "iopub.status.idle": "2023-05-07T00:08:06.188423Z",
     "shell.execute_reply": "2023-05-07T00:08:06.187661Z",
     "shell.execute_reply.started": "2023-05-07T00:08:03.672996Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 14255.58it/s]\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 872/872 [00:00<00:00, 10648.23it/s]\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "USE_BERT_EMBEDDINGS = True\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = create_train_sst2(\n",
    "    num_samples=config[\"num_training_examples\"],\n",
    "    tokenizer_name=config[\"bert_model_name\"],\n",
    "    max_seq_len=config[\"max_sequence_length\"],\n",
    "    device=device,\n",
    "    use_bert_embeddings=USE_BERT_EMBEDDINGS,\n",
    ")\n",
    "\n",
    "test_dataset = create_test_sst2(\n",
    "    tokenizer_name=config[\"bert_model_name\"],\n",
    "    max_seq_len=config[\"max_sequence_length\"],\n",
    "    device=device,\n",
    "    use_bert_embeddings=USE_BERT_EMBEDDINGS,\n",
    ")\n",
    "test_dataloader = DataLoader(test_dataset, shuffle=False, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e37995-84b8-48bd-a7c8-0dba09040369",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c808236-ee63-46fe-aef5-2cfb8bab525f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-07T00:08:06.189918Z",
     "iopub.status.busy": "2023-05-07T00:08:06.189485Z",
     "iopub.status.idle": "2023-05-07T00:08:31.826702Z",
     "shell.execute_reply": "2023-05-07T00:08:31.825822Z",
     "shell.execute_reply.started": "2023-05-07T00:08:06.189883Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 27.04batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 31.29batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 31.29batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:01<00:00, 31.54batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 31.30batch/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.41442395658465236, 80.27522935779817)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_model, original_df, test_loss, test_acc = train_utils.train_bert_model(\n",
    "    train_dataset=train_dataset,\n",
    "    test_dataset=test_dataset,\n",
    "    config=config,\n",
    "    use_bert_embeddings=USE_BERT_EMBEDDINGS,\n",
    ")\n",
    "test_loss, test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98c260f-134c-45a5-a710-a3ced0b55b99",
   "metadata": {},
   "source": [
    "## Adversarial Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38c66c2d-7243-4936-bf4d-a19a24718bad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-07T00:08:31.828665Z",
     "iopub.status.busy": "2023-05-07T00:08:31.828177Z",
     "iopub.status.idle": "2023-05-07T00:08:31.854800Z",
     "shell.execute_reply": "2023-05-07T00:08:31.853958Z",
     "shell.execute_reply.started": "2023-05-07T00:08:31.828638Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def perturb_datapoint(dataset, data_guid, perturbation):\n",
    "    \"\"\"This modifies the dataset in place\"\"\"\n",
    "    device = utils.get_device()\n",
    "    guid, inputs, attn_mask, labels = [t[data_guid] for t in train_dataset.tensors]\n",
    "    assert guid.squeeze() == data_guid\n",
    "\n",
    "    inputs_before = inputs.detach().clone()\n",
    "    inputs += perturbation.to(device)\n",
    "    return inputs_before, inputs\n",
    "\n",
    "\n",
    "def perform_attack(\n",
    "    model,\n",
    "    config,\n",
    "    train_dataset,\n",
    "    test_dataset,\n",
    "    target_test_guid,\n",
    "    target_train_guid=None,\n",
    "    alpha=2e-2,\n",
    "):\n",
    "    infl = None\n",
    "    if target_train_guid is None:\n",
    "        print(\"---Computing Influence Function---\")\n",
    "        infl = influence.compute_influence(\n",
    "            model,\n",
    "            target_test_guid,\n",
    "            param_influence=list(model.classifier.parameters()),\n",
    "            train_dataset=train_dataset,\n",
    "            test_dataset=test_dataset,\n",
    "            use_bert_embeddings=True,\n",
    "            lissa_r=2,\n",
    "            lissa_depth=1,\n",
    "            damping=5e-3,\n",
    "            scale=100,\n",
    "        )\n",
    "\n",
    "        # Most negative influence is most helpful\n",
    "        helpful_idxs = np.argsort(infl)[:10]\n",
    "        target_train_guid = helpful_idxs[0]\n",
    "\n",
    "    print(\"---Computing Input Influence Function---\")\n",
    "    input_infl = influence.compute_input_influence(\n",
    "        model,\n",
    "        target_test_guid,\n",
    "        param_influence=list(model.classifier.parameters()),\n",
    "        train_dataset=train_dataset,\n",
    "        test_dataset=test_dataset,\n",
    "        use_bert_embeddings=True,\n",
    "        lissa_r=2,\n",
    "        lissa_depth=1,\n",
    "        damping=5e-3,\n",
    "        scale=100,\n",
    "        training_indices=[target_train_guid],\n",
    "    )\n",
    "\n",
    "    print(f\"---Perturbing training guid {target_train_guid}---\")\n",
    "    perturb = alpha * input_infl[target_train_guid]\n",
    "    perturb_datapoint(train_dataset, target_train_guid, perturb)\n",
    "\n",
    "    print(\"---Retraining on perturbed data---\")\n",
    "    # Retrain model on perturbed dataset\n",
    "    model, df, full_test_loss, full_test_acc = train_utils.train_bert_model(\n",
    "        train_dataset=train_dataset,\n",
    "        test_dataset=test_dataset,\n",
    "        config=config,\n",
    "        use_bert_embeddings=True,\n",
    "    )\n",
    "    df[\"perturbed_guid\"] = target_train_guid\n",
    "    return model, df, infl, input_infl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83e0d214-c4da-4fd3-9c99-a4c052509a40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-07T00:52:34.743115Z",
     "iopub.status.busy": "2023-05-07T00:52:34.742870Z",
     "iopub.status.idle": "2023-05-07T00:52:34.776733Z",
     "shell.execute_reply": "2023-05-07T00:52:34.775798Z",
     "shell.execute_reply.started": "2023-05-07T00:52:34.743099Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_guid</th>\n",
       "      <th>logits</th>\n",
       "      <th>pred</th>\n",
       "      <th>label</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>497</td>\n",
       "      <td>[0.0020433236, -0.011170415]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.686562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>870</td>\n",
       "      <td>[-0.0993969, -0.13528356]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.675365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>271</td>\n",
       "      <td>[0.0107166935, 0.050429046]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.673488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>695</td>\n",
       "      <td>[-0.43976375, -0.4852701]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.670653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>230</td>\n",
       "      <td>[-0.25980154, -0.21333694]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.670185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>613</td>\n",
       "      <td>[-3.3422766, 3.141655]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>303</td>\n",
       "      <td>[-3.5994592, 2.8959098]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>837</td>\n",
       "      <td>[-3.6050532, 3.4566987]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>443</td>\n",
       "      <td>[-3.6812828, 3.639783]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>334</td>\n",
       "      <td>[-4.114553, 3.8868506]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>700 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     test_guid                        logits  pred  label      loss\n",
       "497        497  [0.0020433236, -0.011170415]     0      0  0.686562\n",
       "870        870     [-0.0993969, -0.13528356]     0      0  0.675365\n",
       "271        271   [0.0107166935, 0.050429046]     1      1  0.673488\n",
       "695        695     [-0.43976375, -0.4852701]     0      0  0.670653\n",
       "230        230    [-0.25980154, -0.21333694]     1      1  0.670185\n",
       "..         ...                           ...   ...    ...       ...\n",
       "613        613        [-3.3422766, 3.141655]     1      1  0.001527\n",
       "303        303       [-3.5994592, 2.8959098]     1      1  0.001509\n",
       "837        837       [-3.6050532, 3.4566987]     1      1  0.000857\n",
       "443        443        [-3.6812828, 3.639783]     1      1  0.000661\n",
       "334        334        [-4.114553, 3.8868506]     1      1  0.000335\n",
       "\n",
       "[700 rows x 5 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_df[original_df.pred == original_df.label].sort_values('loss', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76c62a34-7687-43c3-ba88-66fcc9679de3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-07T00:08:31.856222Z",
     "iopub.status.busy": "2023-05-07T00:08:31.855739Z",
     "iopub.status.idle": "2023-05-07T00:08:31.883143Z",
     "shell.execute_reply": "2023-05-07T00:08:31.882400Z",
     "shell.execute_reply.started": "2023-05-07T00:08:31.856204Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6865621209144592"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST_GUID = 716\n",
    "TEST_GUID = 497\n",
    "\n",
    "baseline_test_loss = original_df[original_df.test_guid == TEST_GUID].loss.squeeze()\n",
    "baseline_test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e57ad744-fabd-4239-90a0-8eaa72b2561f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-07T00:08:31.885812Z",
     "iopub.status.busy": "2023-05-07T00:08:31.885604Z",
     "iopub.status.idle": "2023-05-07T01:19:45.692494Z",
     "shell.execute_reply": "2023-05-07T01:19:45.691751Z",
     "shell.execute_reply.started": "2023-05-07T00:52:55.890073Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Computing Influence Function---\n",
      "LiSSA reps: 2 and num_iterations: 1000\n",
      "Recursion at depth 0: norm is 13.830604\n",
      "Recursion at depth 200: norm is 310.815369\n",
      "Recursion at depth 400: norm is 400.959137\n",
      "Recursion at depth 600: norm is 432.403717\n",
      "Recursion at depth 800: norm is 442.971222\n",
      "Recursion at depth 999: norm is 445.291595\n",
      "Recursion at depth 0: norm is 13.849314\n",
      "Recursion at depth 200: norm is 310.803345\n",
      "Recursion at depth 400: norm is 402.894745\n",
      "Recursion at depth 600: norm is 432.494446\n",
      "Recursion at depth 800: norm is 443.604462\n",
      "Recursion at depth 999: norm is 445.130676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:06<00:00, 149.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Computing Input Influence Function---\n",
      "LiSSA reps: 2 and num_iterations: 1000\n",
      "Recursion at depth 0: norm is 13.806417\n",
      "Recursion at depth 200: norm is 313.570862\n",
      "Recursion at depth 400: norm is 402.886688\n",
      "Recursion at depth 600: norm is 432.520599\n",
      "Recursion at depth 800: norm is 444.473999\n",
      "Recursion at depth 999: norm is 444.417725\n",
      "Recursion at depth 0: norm is 14.480818\n",
      "Recursion at depth 200: norm is 311.267944\n",
      "Recursion at depth 400: norm is 402.693848\n",
      "Recursion at depth 600: norm is 434.224945\n",
      "Recursion at depth 800: norm is 440.267578\n",
      "Recursion at depth 999: norm is 448.659424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:08<00:00, 112.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Perturbing training guid 146---\n",
      "---Retraining on perturbed data---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 29.83batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 30.13batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 30.04batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 30.03batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 29.79batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Computing Influence Function---\n",
      "LiSSA reps: 2 and num_iterations: 1000\n",
      "Recursion at depth 0: norm is 15.687018\n",
      "Recursion at depth 200: norm is 349.274170\n",
      "Recursion at depth 400: norm is 450.368378\n",
      "Recursion at depth 600: norm is 486.081757\n",
      "Recursion at depth 800: norm is 498.160797\n",
      "Recursion at depth 999: norm is 500.448059\n",
      "Recursion at depth 0: norm is 15.503262\n",
      "Recursion at depth 200: norm is 349.021698\n",
      "Recursion at depth 400: norm is 453.112122\n",
      "Recursion at depth 600: norm is 485.510956\n",
      "Recursion at depth 800: norm is 498.992126\n",
      "Recursion at depth 999: norm is 500.939545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:06<00:00, 149.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Computing Input Influence Function---\n",
      "LiSSA reps: 2 and num_iterations: 1000\n",
      "Recursion at depth 0: norm is 15.583508\n",
      "Recursion at depth 200: norm is 352.369141\n",
      "Recursion at depth 400: norm is 452.870331\n",
      "Recursion at depth 600: norm is 486.043640\n",
      "Recursion at depth 800: norm is 499.626282\n",
      "Recursion at depth 999: norm is 499.591919\n",
      "Recursion at depth 0: norm is 16.258253\n",
      "Recursion at depth 200: norm is 350.180359\n",
      "Recursion at depth 400: norm is 452.665771\n",
      "Recursion at depth 600: norm is 488.268982\n",
      "Recursion at depth 800: norm is 494.840302\n",
      "Recursion at depth 999: norm is 504.537476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:09<00:00, 107.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Perturbing training guid 685---\n",
      "---Retraining on perturbed data---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 29.47batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 30.23batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 30.07batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 30.21batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 30.23batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Computing Influence Function---\n",
      "LiSSA reps: 2 and num_iterations: 1000\n",
      "Recursion at depth 0: norm is 16.321352\n",
      "Recursion at depth 200: norm is 362.926178\n",
      "Recursion at depth 400: norm is 467.813629\n",
      "Recursion at depth 600: norm is 505.231750\n",
      "Recursion at depth 800: norm is 517.767822\n",
      "Recursion at depth 999: norm is 520.059448\n",
      "Recursion at depth 0: norm is 16.107344\n",
      "Recursion at depth 200: norm is 362.598480\n",
      "Recursion at depth 400: norm is 470.840057\n",
      "Recursion at depth 600: norm is 504.545197\n",
      "Recursion at depth 800: norm is 518.691223\n",
      "Recursion at depth 999: norm is 520.661194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:06<00:00, 147.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Computing Input Influence Function---\n",
      "LiSSA reps: 2 and num_iterations: 1000\n",
      "Recursion at depth 0: norm is 16.248802\n",
      "Recursion at depth 200: norm is 366.209595\n",
      "Recursion at depth 400: norm is 470.613739\n",
      "Recursion at depth 600: norm is 505.030670\n",
      "Recursion at depth 800: norm is 519.433899\n",
      "Recursion at depth 999: norm is 519.080139\n",
      "Recursion at depth 0: norm is 16.900284\n",
      "Recursion at depth 200: norm is 363.967651\n",
      "Recursion at depth 400: norm is 470.535309\n",
      "Recursion at depth 600: norm is 507.528381\n",
      "Recursion at depth 800: norm is 514.166199\n",
      "Recursion at depth 999: norm is 524.315979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:08<00:00, 120.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Perturbing training guid 920---\n",
      "---Retraining on perturbed data---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 29.14batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 30.05batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 29.97batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 30.01batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 30.07batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Computing Influence Function---\n",
      "LiSSA reps: 2 and num_iterations: 1000\n",
      "Recursion at depth 0: norm is 16.776709\n",
      "Recursion at depth 200: norm is 372.787781\n",
      "Recursion at depth 400: norm is 480.538300\n",
      "Recursion at depth 600: norm is 519.034363\n",
      "Recursion at depth 800: norm is 531.914124\n",
      "Recursion at depth 999: norm is 534.267395\n",
      "Recursion at depth 0: norm is 16.537794\n",
      "Recursion at depth 200: norm is 372.477020\n",
      "Recursion at depth 400: norm is 483.608032\n",
      "Recursion at depth 600: norm is 518.455872\n",
      "Recursion at depth 800: norm is 532.824402\n",
      "Recursion at depth 999: norm is 535.007141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:06<00:00, 143.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Computing Input Influence Function---\n",
      "LiSSA reps: 2 and num_iterations: 1000\n",
      "Recursion at depth 0: norm is 16.698921\n",
      "Recursion at depth 200: norm is 376.125092\n",
      "Recursion at depth 400: norm is 483.395966\n",
      "Recursion at depth 600: norm is 518.817444\n",
      "Recursion at depth 800: norm is 533.589111\n",
      "Recursion at depth 999: norm is 533.149719\n",
      "Recursion at depth 0: norm is 17.365234\n",
      "Recursion at depth 200: norm is 373.968262\n",
      "Recursion at depth 400: norm is 483.402222\n",
      "Recursion at depth 600: norm is 521.470398\n",
      "Recursion at depth 800: norm is 528.118896\n",
      "Recursion at depth 999: norm is 538.658203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:08<00:00, 120.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Perturbing training guid 131---\n",
      "---Retraining on perturbed data---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 29.91batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 30.04batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 30.02batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 30.01batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 30.03batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Computing Influence Function---\n",
      "LiSSA reps: 2 and num_iterations: 1000\n",
      "Recursion at depth 0: norm is 16.947731\n",
      "Recursion at depth 200: norm is 376.468536\n",
      "Recursion at depth 400: norm is 485.480774\n",
      "Recursion at depth 600: norm is 524.282043\n",
      "Recursion at depth 800: norm is 537.295105\n",
      "Recursion at depth 999: norm is 539.736755\n",
      "Recursion at depth 0: norm is 16.693722\n",
      "Recursion at depth 200: norm is 376.155090\n",
      "Recursion at depth 400: norm is 488.640350\n",
      "Recursion at depth 600: norm is 524.007324\n",
      "Recursion at depth 800: norm is 538.372803\n",
      "Recursion at depth 999: norm is 540.655212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:06<00:00, 147.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Computing Input Influence Function---\n",
      "LiSSA reps: 2 and num_iterations: 1000\n",
      "Recursion at depth 0: norm is 16.869684\n",
      "Recursion at depth 200: norm is 379.934998\n",
      "Recursion at depth 400: norm is 488.224854\n",
      "Recursion at depth 600: norm is 524.116089\n",
      "Recursion at depth 800: norm is 539.290771\n",
      "Recursion at depth 999: norm is 538.798218\n",
      "Recursion at depth 0: norm is 17.536266\n",
      "Recursion at depth 200: norm is 377.769562\n",
      "Recursion at depth 400: norm is 488.342285\n",
      "Recursion at depth 600: norm is 526.871399\n",
      "Recursion at depth 800: norm is 533.519165\n",
      "Recursion at depth 999: norm is 544.154114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:09<00:00, 108.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Perturbing training guid 867---\n",
      "---Retraining on perturbed data---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e1f472b731547f4a5577b8470bab959",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016670745000010357, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 28.98batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 30.09batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 30.19batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 30.02batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 30.05batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Computing Influence Function---\n",
      "LiSSA reps: 2 and num_iterations: 1000\n",
      "Recursion at depth 0: norm is 17.054840\n",
      "Recursion at depth 200: norm is 378.969788\n",
      "Recursion at depth 400: norm is 489.129395\n",
      "Recursion at depth 600: norm is 527.901062\n",
      "Recursion at depth 800: norm is 540.914490\n",
      "Recursion at depth 999: norm is 543.728699\n",
      "Recursion at depth 0: norm is 16.794306\n",
      "Recursion at depth 200: norm is 379.287292\n",
      "Recursion at depth 400: norm is 492.098999\n",
      "Recursion at depth 600: norm is 527.523865\n",
      "Recursion at depth 800: norm is 542.232910\n",
      "Recursion at depth 999: norm is 544.948669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:06<00:00, 146.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Computing Input Influence Function---\n",
      "LiSSA reps: 2 and num_iterations: 1000\n",
      "Recursion at depth 0: norm is 16.974543\n",
      "Recursion at depth 200: norm is 382.689362\n",
      "Recursion at depth 400: norm is 491.732819\n",
      "Recursion at depth 600: norm is 527.951111\n",
      "Recursion at depth 800: norm is 543.403503\n",
      "Recursion at depth 999: norm is 542.795471\n",
      "Recursion at depth 0: norm is 17.645317\n",
      "Recursion at depth 200: norm is 380.455078\n",
      "Recursion at depth 400: norm is 492.186829\n",
      "Recursion at depth 600: norm is 530.765259\n",
      "Recursion at depth 800: norm is 537.337524\n",
      "Recursion at depth 999: norm is 548.040344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:08<00:00, 115.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Perturbing training guid 911---\n",
      "---Retraining on perturbed data---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 29.34batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 30.04batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 30.04batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 30.14batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 29.99batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Computing Influence Function---\n",
      "LiSSA reps: 2 and num_iterations: 1000\n",
      "Recursion at depth 0: norm is 17.347719\n",
      "Recursion at depth 200: norm is 385.858215\n",
      "Recursion at depth 400: norm is 498.396759\n",
      "Recursion at depth 600: norm is 538.009460\n",
      "Recursion at depth 800: norm is 551.000122\n",
      "Recursion at depth 999: norm is 553.751526\n",
      "Recursion at depth 0: norm is 17.060331\n",
      "Recursion at depth 200: norm is 385.773651\n",
      "Recursion at depth 400: norm is 501.779877\n",
      "Recursion at depth 600: norm is 537.744141\n",
      "Recursion at depth 800: norm is 552.808655\n",
      "Recursion at depth 999: norm is 554.917358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:06<00:00, 144.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Computing Input Influence Function---\n",
      "LiSSA reps: 2 and num_iterations: 1000\n",
      "Recursion at depth 0: norm is 17.254351\n",
      "Recursion at depth 200: norm is 389.463531\n",
      "Recursion at depth 400: norm is 501.295929\n",
      "Recursion at depth 600: norm is 537.377014\n",
      "Recursion at depth 800: norm is 553.889771\n",
      "Recursion at depth 999: norm is 553.747314\n",
      "Recursion at depth 0: norm is 17.940121\n",
      "Recursion at depth 200: norm is 387.318146\n",
      "Recursion at depth 400: norm is 501.673035\n",
      "Recursion at depth 600: norm is 540.898682\n",
      "Recursion at depth 800: norm is 547.328125\n",
      "Recursion at depth 999: norm is 558.003662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:09<00:00, 107.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Perturbing training guid 183---\n",
      "---Retraining on perturbed data---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 27.94batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 28.47batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 30.03batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 28.87batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 29.23batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Computing Influence Function---\n",
      "LiSSA reps: 2 and num_iterations: 1000\n",
      "Recursion at depth 0: norm is 17.774250\n",
      "Recursion at depth 200: norm is 396.140320\n",
      "Recursion at depth 400: norm is 512.147583\n",
      "Recursion at depth 600: norm is 553.026550\n",
      "Recursion at depth 800: norm is 566.036560\n",
      "Recursion at depth 999: norm is 569.827576\n",
      "Recursion at depth 0: norm is 17.489773\n",
      "Recursion at depth 200: norm is 396.125519\n",
      "Recursion at depth 400: norm is 515.583435\n",
      "Recursion at depth 600: norm is 552.404175\n",
      "Recursion at depth 800: norm is 568.297913\n",
      "Recursion at depth 999: norm is 570.307556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:07<00:00, 141.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Computing Input Influence Function---\n",
      "LiSSA reps: 2 and num_iterations: 1000\n",
      "Recursion at depth 0: norm is 17.686131\n",
      "Recursion at depth 200: norm is 399.852814\n",
      "Recursion at depth 400: norm is 515.068787\n",
      "Recursion at depth 600: norm is 552.106506\n",
      "Recursion at depth 800: norm is 568.849060\n",
      "Recursion at depth 999: norm is 568.734314\n",
      "Recursion at depth 0: norm is 18.390631\n",
      "Recursion at depth 200: norm is 397.482758\n",
      "Recursion at depth 400: norm is 515.575012\n",
      "Recursion at depth 600: norm is 555.962463\n",
      "Recursion at depth 800: norm is 562.567688\n",
      "Recursion at depth 999: norm is 572.964355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:09<00:00, 109.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Perturbing training guid 333---\n",
      "---Retraining on perturbed data---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 29.34batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 30.06batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 30.24batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 30.02batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 30.04batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Computing Influence Function---\n",
      "LiSSA reps: 2 and num_iterations: 1000\n",
      "Recursion at depth 0: norm is 18.117043\n",
      "Recursion at depth 200: norm is 403.823883\n",
      "Recursion at depth 400: norm is 522.251770\n",
      "Recursion at depth 600: norm is 563.839233\n",
      "Recursion at depth 800: norm is 576.983154\n",
      "Recursion at depth 999: norm is 580.884949\n",
      "Recursion at depth 0: norm is 17.822470\n",
      "Recursion at depth 200: norm is 403.666534\n",
      "Recursion at depth 400: norm is 525.571899\n",
      "Recursion at depth 600: norm is 563.074768\n",
      "Recursion at depth 800: norm is 579.278442\n",
      "Recursion at depth 999: norm is 581.391663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:06<00:00, 147.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Computing Input Influence Function---\n",
      "LiSSA reps: 2 and num_iterations: 1000\n",
      "Recursion at depth 0: norm is 18.046347\n",
      "Recursion at depth 200: norm is 407.519012\n",
      "Recursion at depth 400: norm is 525.048096\n",
      "Recursion at depth 600: norm is 562.781067\n",
      "Recursion at depth 800: norm is 579.856323\n",
      "Recursion at depth 999: norm is 579.771362\n",
      "Recursion at depth 0: norm is 18.746189\n",
      "Recursion at depth 200: norm is 405.259186\n",
      "Recursion at depth 400: norm is 525.513062\n",
      "Recursion at depth 600: norm is 566.707092\n",
      "Recursion at depth 800: norm is 573.350464\n",
      "Recursion at depth 999: norm is 584.062622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:09<00:00, 109.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Perturbing training guid 843---\n",
      "---Retraining on perturbed data---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 29.94batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 30.03batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 30.02batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 30.10batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 30.19batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Computing Influence Function---\n",
      "LiSSA reps: 2 and num_iterations: 1000\n",
      "Recursion at depth 0: norm is 18.141100\n",
      "Recursion at depth 200: norm is 404.502472\n",
      "Recursion at depth 400: norm is 522.870300\n",
      "Recursion at depth 600: norm is 564.650940\n",
      "Recursion at depth 800: norm is 577.708557\n",
      "Recursion at depth 999: norm is 581.674500\n",
      "Recursion at depth 0: norm is 17.836382\n",
      "Recursion at depth 200: norm is 404.141693\n",
      "Recursion at depth 400: norm is 526.183350\n",
      "Recursion at depth 600: norm is 563.671204\n",
      "Recursion at depth 800: norm is 580.138123\n",
      "Recursion at depth 999: norm is 582.219238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:06<00:00, 148.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Computing Input Influence Function---\n",
      "LiSSA reps: 2 and num_iterations: 1000\n",
      "Recursion at depth 0: norm is 18.051645\n",
      "Recursion at depth 200: norm is 408.585968\n",
      "Recursion at depth 400: norm is 525.826538\n",
      "Recursion at depth 600: norm is 563.662964\n",
      "Recursion at depth 800: norm is 580.642761\n",
      "Recursion at depth 999: norm is 580.527527\n",
      "Recursion at depth 0: norm is 18.759806\n",
      "Recursion at depth 200: norm is 405.813110\n",
      "Recursion at depth 400: norm is 526.589111\n",
      "Recursion at depth 600: norm is 567.518860\n",
      "Recursion at depth 800: norm is 574.171387\n",
      "Recursion at depth 999: norm is 585.055420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:08<00:00, 120.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Perturbing training guid 119---\n",
      "---Retraining on perturbed data---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 28.94batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 30.01batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 29.88batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 30.17batch/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:02<00:00, 29.85batch/s]\n"
     ]
    }
   ],
   "source": [
    "# target_train_guid = 262\n",
    "\n",
    "hist = {\n",
    "    \"loss_df\": [],\n",
    "    \"influence\": [],\n",
    "    \"input_influence\": [],\n",
    "}\n",
    "model = full_model\n",
    "for i in range(15):\n",
    "    model, loss_df, infl, input_infl = perform_attack(\n",
    "        model=model,\n",
    "        config=config,\n",
    "        train_dataset=train_dataset,\n",
    "        test_dataset=test_dataset,\n",
    "        target_test_guid=TEST_GUID,\n",
    "        alpha=5e-1,\n",
    "        # target_train_guid=target_train_guid,\n",
    "    )\n",
    "    loss_df[\"iter\"] = i\n",
    "\n",
    "    hist[\"loss_df\"].append(loss_df)\n",
    "    hist[\"influence\"].append(infl)\n",
    "    hist[\"input_influence\"].append(input_infl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "91b0cab9-7c9e-4929-94c1-7eddb16b8ea2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-07T01:19:45.733126Z",
     "iopub.status.busy": "2023-05-07T01:19:45.732953Z",
     "iopub.status.idle": "2023-05-07T01:19:45.763540Z",
     "shell.execute_reply": "2023-05-07T01:19:45.762713Z",
     "shell.execute_reply.started": "2023-05-07T01:19:45.733112Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_guid</th>\n",
       "      <th>logits</th>\n",
       "      <th>pred</th>\n",
       "      <th>label</th>\n",
       "      <th>loss</th>\n",
       "      <th>perturbed_guid</th>\n",
       "      <th>iter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>497</td>\n",
       "      <td>[-0.118081115, 0.1089515]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.813093</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>497</td>\n",
       "      <td>[-0.1613373, 0.15220653]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.862158</td>\n",
       "      <td>685</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>497</td>\n",
       "      <td>[-0.19281432, 0.18368623]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.899013</td>\n",
       "      <td>920</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>497</td>\n",
       "      <td>[-0.20458043, 0.19545211]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.913035</td>\n",
       "      <td>131</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>497</td>\n",
       "      <td>[-0.21231705, 0.20318845]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.922327</td>\n",
       "      <td>867</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>497</td>\n",
       "      <td>[-0.23281749, 0.2236888]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.947227</td>\n",
       "      <td>911</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>497</td>\n",
       "      <td>[-0.26563478, 0.25650555]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.987916</td>\n",
       "      <td>183</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>497</td>\n",
       "      <td>[-0.29135677, 0.2822266]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.020512</td>\n",
       "      <td>333</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>497</td>\n",
       "      <td>[-0.29223296, 0.2831043]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.021634</td>\n",
       "      <td>843</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>497</td>\n",
       "      <td>[-0.29912966, 0.29000124]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.030484</td>\n",
       "      <td>119</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     test_guid                     logits  pred  label      loss  \\\n",
       "497        497  [-0.118081115, 0.1089515]     1      0  0.813093   \n",
       "497        497   [-0.1613373, 0.15220653]     1      0  0.862158   \n",
       "497        497  [-0.19281432, 0.18368623]     1      0  0.899013   \n",
       "497        497  [-0.20458043, 0.19545211]     1      0  0.913035   \n",
       "497        497  [-0.21231705, 0.20318845]     1      0  0.922327   \n",
       "497        497   [-0.23281749, 0.2236888]     1      0  0.947227   \n",
       "497        497  [-0.26563478, 0.25650555]     1      0  0.987916   \n",
       "497        497   [-0.29135677, 0.2822266]     1      0  1.020512   \n",
       "497        497   [-0.29223296, 0.2831043]     1      0  1.021634   \n",
       "497        497  [-0.29912966, 0.29000124]     1      0  1.030484   \n",
       "\n",
       "     perturbed_guid  iter  \n",
       "497             146     0  \n",
       "497             685     1  \n",
       "497             920     2  \n",
       "497             131     3  \n",
       "497             867     4  \n",
       "497             911     5  \n",
       "497             183     6  \n",
       "497             333     7  \n",
       "497             843     8  \n",
       "497             119     9  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat(hist['loss_df'])\n",
    "df[df.test_guid == TEST_GUID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70623645-8add-4d07-813d-f85e59916725",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcd3b12-0250-4e32-a04d-0277f3130ad1",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T00:48:23.247188Z",
     "iopub.status.idle": "2023-05-07T00:48:23.247398Z",
     "shell.execute_reply": "2023-05-07T00:48:23.247308Z",
     "shell.execute_reply.started": "2023-05-07T00:48:23.247298Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df0 = loss_hist[0]\n",
    "df1 = loss_hist[1]\n",
    "df2 = loss_hist[2]\n",
    "df3 = loss_hist[3]\n",
    "df4 = loss_hist[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbd3a1d-b5ef-400b-ae31-2246794baaca",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T00:48:23.248291Z",
     "iopub.status.idle": "2023-05-07T00:48:23.248499Z",
     "shell.execute_reply": "2023-05-07T00:48:23.248408Z",
     "shell.execute_reply.started": "2023-05-07T00:48:23.248398Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df0[df0.test_guid == TEST_GUID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cc4957-45fe-4a3b-ac38-44aa42ac93fa",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T00:48:23.249078Z",
     "iopub.status.idle": "2023-05-07T00:48:23.249290Z",
     "shell.execute_reply": "2023-05-07T00:48:23.249199Z",
     "shell.execute_reply.started": "2023-05-07T00:48:23.249189Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df1[df1.test_guid == TEST_GUID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50f6221-6696-4e2f-91ce-de24801b5b7f",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T00:48:23.250214Z",
     "iopub.status.idle": "2023-05-07T00:48:23.250423Z",
     "shell.execute_reply": "2023-05-07T00:48:23.250334Z",
     "shell.execute_reply.started": "2023-05-07T00:48:23.250324Z"
    }
   },
   "outputs": [],
   "source": [
    "df2[df2.test_guid == TEST_GUID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03718299-1e99-4448-8697-6c599aa3e807",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T00:48:23.251472Z",
     "iopub.status.idle": "2023-05-07T00:48:23.251695Z",
     "shell.execute_reply": "2023-05-07T00:48:23.251604Z",
     "shell.execute_reply.started": "2023-05-07T00:48:23.251594Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df3[df3.test_guid == TEST_GUID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa802b7-fbc5-464b-a81c-ae33e94acf0b",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T00:48:23.252394Z",
     "iopub.status.idle": "2023-05-07T00:48:23.252615Z",
     "shell.execute_reply": "2023-05-07T00:48:23.252512Z",
     "shell.execute_reply.started": "2023-05-07T00:48:23.252503Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df4[df4.test_guid == TEST_GUID]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee79f5b-b737-47a6-adc9-959f402e4a3e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd99cc36-5593-42ad-85c4-aa450128582d",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T00:48:23.253953Z",
     "iopub.status.idle": "2023-05-07T00:48:23.254176Z",
     "shell.execute_reply": "2023-05-07T00:48:23.254082Z",
     "shell.execute_reply.started": "2023-05-07T00:48:23.254072Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model2, loss_df2 = perform_attack(model, config, train_dataset, test_dataset, TEST_GUID)\n",
    "loss_df2[loss_df2.test_guid == TEST_GUID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adae75ff-6482-4f28-b01f-3ceb188e4836",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T00:48:23.255250Z",
     "iopub.status.idle": "2023-05-07T00:48:23.255597Z",
     "shell.execute_reply": "2023-05-07T00:48:23.255454Z",
     "shell.execute_reply.started": "2023-05-07T00:48:23.255439Z"
    }
   },
   "outputs": [],
   "source": [
    "model3, loss_df3 = perform_attack(\n",
    "    model2, config, train_dataset, test_dataset, TEST_GUID\n",
    ")\n",
    "loss_df3[loss_df3.test_guid == TEST_GUID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1761d131-4840-44c0-be1d-6939cd4355f1",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T00:48:23.257194Z",
     "iopub.status.idle": "2023-05-07T00:48:23.257451Z",
     "shell.execute_reply": "2023-05-07T00:48:23.257351Z",
     "shell.execute_reply.started": "2023-05-07T00:48:23.257340Z"
    }
   },
   "outputs": [],
   "source": [
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cded59fc-a91e-4172-ac82-03721c8a96b1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Compute Influence Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc021eb5-80e7-4766-aa3e-5c3e62670838",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T00:48:23.258247Z",
     "iopub.status.idle": "2023-05-07T00:48:23.258464Z",
     "shell.execute_reply": "2023-05-07T00:48:23.258372Z",
     "shell.execute_reply.started": "2023-05-07T00:48:23.258362Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TEST_GUID = 716\n",
    "\n",
    "infl = influence.compute_influence(\n",
    "    full_model,\n",
    "    TEST_GUID,\n",
    "    param_influence=list(full_model.classifier.parameters()),\n",
    "    train_dataset=train_dataset,\n",
    "    test_dataset=test_dataset,\n",
    "    use_bert_embeddings=USE_BERT_EMBEDDINGS,\n",
    "    lissa_r=2,\n",
    "    lissa_depth=1,\n",
    "    damping=5e-3,\n",
    "    scale=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79a9e73-027e-44e0-8f7e-3db986781519",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T00:48:23.259734Z",
     "iopub.status.idle": "2023-05-07T00:48:23.260029Z",
     "shell.execute_reply": "2023-05-07T00:48:23.259919Z",
     "shell.execute_reply.started": "2023-05-07T00:48:23.259883Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Most negative influence is most helpful\n",
    "helpful_idxs = np.argsort(infl)[:10]\n",
    "helpful_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616eba86-7603-47b1-9d1e-310ba5f91297",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T00:48:23.261132Z",
     "iopub.status.idle": "2023-05-07T00:48:23.261364Z",
     "shell.execute_reply": "2023-05-07T00:48:23.261270Z",
     "shell.execute_reply.started": "2023-05-07T00:48:23.261260Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.take(infl, helpful_idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d02bf0-e609-4222-997a-4891051e762b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Compute Input Influence Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a305507-f74f-434c-8c00-be1d73eef30c",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T00:48:23.262135Z",
     "iopub.status.idle": "2023-05-07T00:48:23.262346Z",
     "shell.execute_reply": "2023-05-07T00:48:23.262255Z",
     "shell.execute_reply.started": "2023-05-07T00:48:23.262246Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_infl = influence.compute_input_influence(\n",
    "    full_model,\n",
    "    TEST_GUID,\n",
    "    param_influence=list(full_model.classifier.parameters()),\n",
    "    train_dataset=train_dataset,\n",
    "    test_dataset=test_dataset,\n",
    "    use_bert_embeddings=USE_BERT_EMBEDDINGS,\n",
    "    lissa_r=2,\n",
    "    lissa_depth=1,\n",
    "    damping=5e-3,\n",
    "    scale=100,\n",
    "    training_indices=helpful_idxs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453d8bbb-17b9-4a0b-a9ef-46693bdf3685",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T00:48:23.262969Z",
     "iopub.status.idle": "2023-05-07T00:48:23.263164Z",
     "shell.execute_reply": "2023-05-07T00:48:23.263077Z",
     "shell.execute_reply.started": "2023-05-07T00:48:23.263068Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_idx = helpful_idxs[0]\n",
    "best_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6333341-1e0f-4b2b-9ea6-4eb6a0fe2887",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Perturb the Best Idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91765c3-06a2-4ad0-8ea2-0f661ce17174",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T00:48:23.263717Z",
     "iopub.status.idle": "2023-05-07T00:48:23.264024Z",
     "shell.execute_reply": "2023-05-07T00:48:23.263825Z",
     "shell.execute_reply.started": "2023-05-07T00:48:23.263816Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_guid(dataset, data_guid):\n",
    "    pass\n",
    "\n",
    "\n",
    "def perturb_datapoint(dataset, data_guid, perturbation):\n",
    "    \"\"\"This modifies the dataset in place\"\"\"\n",
    "    device = utils.get_device()\n",
    "    guid, inputs, attn_mask, labels = [t[data_guid] for t in train_dataset.tensors]\n",
    "    assert guid.squeeze() == data_guid\n",
    "\n",
    "    inputs_before = inputs.detach().clone()\n",
    "    inputs += perturbation.to(device)\n",
    "    return inputs_before, inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a679d057-fba5-43b5-80e0-87a1cc0182dd",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T00:48:23.265061Z",
     "iopub.status.idle": "2023-05-07T00:48:23.265259Z",
     "shell.execute_reply": "2023-05-07T00:48:23.265172Z",
     "shell.execute_reply.started": "2023-05-07T00:48:23.265162Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "alpha = 1e-2\n",
    "\n",
    "perturb = alpha * input_infl[best_idx]\n",
    "before, after = perturb_datapoint(train_dataset, best_idx, perturb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edd2dac-5be5-4722-92d9-53477d7f76ac",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Retrain model with new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355e9119-2b25-402d-ae45-19c9c363a476",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T00:48:23.266413Z",
     "iopub.status.idle": "2023-05-07T00:48:23.266621Z",
     "shell.execute_reply": "2023-05-07T00:48:23.266521Z",
     "shell.execute_reply.started": "2023-05-07T00:48:23.266511Z"
    }
   },
   "outputs": [],
   "source": [
    "model, df, full_test_loss, full_test_acc = train_utils.train_bert_model(\n",
    "    train_dataset=train_dataset,\n",
    "    test_dataset=test_dataset,\n",
    "    config=config,\n",
    "    use_bert_embeddings=USE_BERT_EMBEDDINGS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b824ce68-ecd5-4ea3-9210-2feb4415a281",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T00:48:23.267253Z",
     "iopub.status.idle": "2023-05-07T00:48:23.267448Z",
     "shell.execute_reply": "2023-05-07T00:48:23.267362Z",
     "shell.execute_reply.started": "2023-05-07T00:48:23.267353Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_loss = df[df.test_guid == TEST_GUID].loss.squeeze()\n",
    "test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6aa9224-8ac0-4eff-8d81-ce14637d31d1",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T00:48:23.268254Z",
     "iopub.status.idle": "2023-05-07T00:48:23.268447Z",
     "shell.execute_reply": "2023-05-07T00:48:23.268361Z",
     "shell.execute_reply.started": "2023-05-07T00:48:23.268352Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[df.test_guid == TEST_GUID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04445757-1ab6-45a4-883b-1d5c4e60e032",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T00:48:23.269452Z",
     "iopub.status.idle": "2023-05-07T00:48:23.269670Z",
     "shell.execute_reply": "2023-05-07T00:48:23.269582Z",
     "shell.execute_reply.started": "2023-05-07T00:48:23.269572Z"
    }
   },
   "outputs": [],
   "source": [
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63422e9-1f40-44ce-9902-455dfdcf7bff",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T00:48:23.270488Z",
     "iopub.status.idle": "2023-05-07T00:48:23.270697Z",
     "shell.execute_reply": "2023-05-07T00:48:23.270610Z",
     "shell.execute_reply.started": "2023-05-07T00:48:23.270600Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd2805d-c783-4d22-96f0-ff44276855dd",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T00:48:23.271156Z",
     "iopub.status.idle": "2023-05-07T00:48:23.271356Z",
     "shell.execute_reply": "2023-05-07T00:48:23.271269Z",
     "shell.execute_reply.started": "2023-05-07T00:48:23.271259Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ba1c52-4cee-4e2f-b54f-ee96d3684f35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80a68aa-216f-4954-8785-23f41e3cc9c1",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T00:48:23.271936Z",
     "iopub.status.idle": "2023-05-07T00:48:23.272132Z",
     "shell.execute_reply": "2023-05-07T00:48:23.272044Z",
     "shell.execute_reply.started": "2023-05-07T00:48:23.272035Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "guid, inputs, attn_mask, labels = [t[data_guid] for t in train_dataset.tensors]\n",
    "\n",
    "inputs[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a69a0e5-15b5-458e-8828-d5ef82c068b2",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T00:48:23.273006Z",
     "iopub.status.idle": "2023-05-07T00:48:23.273220Z",
     "shell.execute_reply": "2023-05-07T00:48:23.273128Z",
     "shell.execute_reply.started": "2023-05-07T00:48:23.273119Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "guid, inputs, attn_mask, labels = [t[262] for t in train_dataset.tensors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08f607a-b99a-4d15-ae35-b6984969bba0",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T00:48:23.274298Z",
     "iopub.status.idle": "2023-05-07T00:48:23.274506Z",
     "shell.execute_reply": "2023-05-07T00:48:23.274417Z",
     "shell.execute_reply.started": "2023-05-07T00:48:23.274408Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f81f2f-76c4-4786-b760-bb978bd550ae",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T00:48:23.275627Z",
     "iopub.status.idle": "2023-05-07T00:48:23.275831Z",
     "shell.execute_reply": "2023-05-07T00:48:23.275743Z",
     "shell.execute_reply.started": "2023-05-07T00:48:23.275734Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# inputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743304c1-9f64-43ea-b2e3-9371fc812e75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15407823-c8f9-4152-917f-90f2afbed45f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5534f87-9724-4f8b-9bdb-7a1eb7e74861",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T00:48:23.276782Z",
     "iopub.status.idle": "2023-05-07T00:48:23.276978Z",
     "shell.execute_reply": "2023-05-07T00:48:23.276891Z",
     "shell.execute_reply.started": "2023-05-07T00:48:23.276882Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370d28b1-c85a-4f74-957c-d145fc788b47",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T00:48:23.277748Z",
     "iopub.status.idle": "2023-05-07T00:48:23.277943Z",
     "shell.execute_reply": "2023-05-07T00:48:23.277857Z",
     "shell.execute_reply.started": "2023-05-07T00:48:23.277848Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs += perturb.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4840791b-35a4-494f-ad0a-3e81b51b72b9",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T00:48:23.278801Z",
     "iopub.status.idle": "2023-05-07T00:48:23.278999Z",
     "shell.execute_reply": "2023-05-07T00:48:23.278911Z",
     "shell.execute_reply.started": "2023-05-07T00:48:23.278902Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e562a8f-b82e-478a-9709-b3e390de60f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6307729d-8f62-474c-a17f-554f0bd04db2",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T00:48:23.279977Z",
     "iopub.status.idle": "2023-05-07T00:48:23.280178Z",
     "shell.execute_reply": "2023-05-07T00:48:23.280090Z",
     "shell.execute_reply.started": "2023-05-07T00:48:23.280080Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_infl[262]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b985181-9737-477a-b767-7768cee06604",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T00:48:23.280889Z",
     "iopub.status.idle": "2023-05-07T00:48:23.281083Z",
     "shell.execute_reply": "2023-05-07T00:48:23.280997Z",
     "shell.execute_reply.started": "2023-05-07T00:48:23.280987Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"input_infl.pkl\", \"wb\") as fh:\n",
    "    pickle.dump(input_infl, fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e83797-584e-4cb0-834b-9d67ab90092d",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T00:48:23.281912Z",
     "iopub.status.idle": "2023-05-07T00:48:23.282116Z",
     "shell.execute_reply": "2023-05-07T00:48:23.282027Z",
     "shell.execute_reply.started": "2023-05-07T00:48:23.282018Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "262 in helpful_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7315cae-79d4-44e6-a46f-5747b6432232",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T00:48:23.283197Z",
     "iopub.status.idle": "2023-05-07T00:48:23.283393Z",
     "shell.execute_reply": "2023-05-07T00:48:23.283306Z",
     "shell.execute_reply.started": "2023-05-07T00:48:23.283296Z"
    }
   },
   "outputs": [],
   "source": [
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83554cab-505a-4625-af7c-7f8bd67a112d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b535adce-67f9-4691-b378-549184a65661",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T00:48:23.284179Z",
     "iopub.status.idle": "2023-05-07T00:48:23.284373Z",
     "shell.execute_reply": "2023-05-07T00:48:23.284286Z",
     "shell.execute_reply.started": "2023-05-07T00:48:23.284277Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors, Word2Vec\n",
    "\n",
    "w2v = KeyedVectors.load(\"word2vec/glove-twitter-100.kv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91972328-d099-4c87-a2aa-affe2b49bcc2",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T00:48:23.286191Z",
     "iopub.status.idle": "2023-05-07T00:48:23.286410Z",
     "shell.execute_reply": "2023-05-07T00:48:23.286317Z",
     "shell.execute_reply.started": "2023-05-07T00:48:23.286306Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "w2v[\"spielberg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a2e76f-7b63-4b43-8c56-88a3dfe08efa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e3d843-28ab-4021-afc7-46e3f6793576",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32778a7-5a9e-4dda-9716-4d1cfcbb97f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
